{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7868af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Add repo root to path\n",
    "repo_root = Path().resolve().parents[2]\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "from modules._import_helper import safe_import_from\n",
    "\n",
    "# Import utilities and Bayesian regression\n",
    "set_seed = safe_import_from('00_repo_standards.src.mlphys_core.seeding', 'set_seed')\n",
    "BayesianLinearRegression, posterior_predictive = safe_import_from(\n",
    "    '02_stat_inference_uq.src.bayesian_regression',\n",
    "    'BayesianLinearRegression', 'posterior_predictive'\n",
    ")\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "reports_dir = Path(\"../reports\")\n",
    "reports_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"âœ… Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb60574",
   "metadata": {},
   "source": [
    "## 1. Intuition: What is Bayesian Linear Regression?\n",
    "\n",
    "**Key differences from standard (frequentist) linear regression:**\n",
    "- **Frequentist**: Finds single \"best\" parameters $\\hat{w}$ that minimize loss\n",
    "- **Bayesian**: Computes a **distribution** over parameters $p(w | \\text{data})$\n",
    "- **Why it matters**: Bayesian gives you uncertainty bands on predictions, not just point estimates\n",
    "- **When predictions are uncertain** (e.g., far from training data), Bayesian credible bands widen automatically\n",
    "- **Requires**: A prior belief $p(w)$ about parameters before seeing data\n",
    "\n",
    "**Physics analogy**: \n",
    "- Frequentist: \"The spring constant is 2.5 N/m\" (point estimate)\n",
    "- Bayesian: \"The spring constant is likely 2.5 Â± 0.3 N/m with 95% probability\" (distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e790b",
   "metadata": {},
   "source": [
    "## 2. Minimal Math: Bayesian Inference\n",
    "\n",
    "**Model:**\n",
    "$$y = Xw + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I)$$\n",
    "\n",
    "**Prior** (what we believe before seeing data):\n",
    "$$p(w) = \\mathcal{N}(w_0, \\Sigma_0)$$\n",
    "\n",
    "**Likelihood** (probability of data given parameters):\n",
    "$$p(y | X, w) = \\mathcal{N}(Xw, \\sigma^2 I)$$\n",
    "\n",
    "**Bayes' Rule:**\n",
    "$$p(w | X, y) = \\frac{p(y | X, w) \\, p(w)}{p(y | X)} \\propto p(y | X, w) \\, p(w)$$\n",
    "\n",
    "**Posterior** (what we believe after seeing data):\n",
    "$$p(w | X, y) = \\mathcal{N}(w_N, \\Sigma_N)$$\n",
    "\n",
    "where:\n",
    "- Posterior precision: $\\Lambda_N = \\Lambda_0 + \\frac{1}{\\sigma^2} X^T X$\n",
    "- Posterior covariance: $\\Sigma_N = \\Lambda_N^{-1}$\n",
    "- Posterior mean: $w_N = \\Sigma_N \\left( \\Lambda_0 w_0 + \\frac{1}{\\sigma^2} X^T y \\right)$\n",
    "\n",
    "**Posterior predictive distribution** (predictions with uncertainty):\n",
    "$$p(y_* | x_*, X, y) = \\mathcal{N}(x_*^T w_N, \\, \\sigma^2 + x_*^T \\Sigma_N x_*)$$\n",
    "\n",
    "**Interpretation**: Variance has two terms:\n",
    "1. $\\sigma^2$ = aleatoric (measurement noise)\n",
    "2. $x_*^T \\Sigma_N x_*$ = epistemic (parameter uncertainty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a878da0",
   "metadata": {},
   "source": [
    "## 3. Implementation: Using BayesianLinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba00b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data: y = 2x - 1 + noise\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_data(n_samples: int, noise_std: float = 0.3):\n",
    "    \"\"\"Generate linear data with noise.\"\"\"\n",
    "    X = np.linspace(-2, 2, n_samples).reshape(-1, 1)\n",
    "    y_true = 2 * X.ravel() - 1  # True function: y = 2x - 1\n",
    "    y = y_true + np.random.normal(0, noise_std, size=n_samples)\n",
    "    return X, y, y_true\n",
    "\n",
    "# Training data\n",
    "n_train = 20\n",
    "X_train, y_train, _ = generate_data(n_train, noise_std=0.3)\n",
    "\n",
    "# Test data (including extrapolation region)\n",
    "X_test = np.linspace(-3, 3, 200).reshape(-1, 1)\n",
    "y_test_true = 2 * X_test.ravel() - 1\n",
    "\n",
    "print(f\"Training data: {n_train} points in [{X_train.min():.1f}, {X_train.max():.1f}]\")\n",
    "print(f\"Test range: [{X_test.min():.1f}, {X_test.max():.1f}] (includes extrapolation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e842fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Bayesian model with weakly informative prior\n",
    "bayes_model = BayesianLinearRegression(\n",
    "    noise_variance=0.3**2,\n",
    "    fit_intercept=False  # We'll manually add intercept column\n",
    ")\n",
    "\n",
    "# Add intercept column to X\n",
    "X_train_aug = np.column_stack([np.ones(len(X_train)), X_train])\n",
    "X_test_aug = np.column_stack([np.ones(len(X_test)), X_test])\n",
    "\n",
    "bayes_model.fit(X_train_aug, y_train)\n",
    "\n",
    "print(\"\\n=== Bayesian Linear Regression Results ===\")\n",
    "print(f\"Posterior mean weights: {bayes_model.posterior_mean_}\")\n",
    "print(f\"True weights: [intercept=-1.0, slope=2.0]\")\n",
    "print(f\"\\nPosterior covariance (uncertainty in weights):\")\n",
    "print(bayes_model.posterior_cov_)\n",
    "print(f\"\\nStd of intercept: {np.sqrt(bayes_model.posterior_cov_[0,0]):.3f}\")\n",
    "print(f\"Std of slope: {np.sqrt(bayes_model.posterior_cov_[1,1]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daedaac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get posterior predictive distribution\n",
    "y_pred_mean, y_pred_std = bayes_model.predict(X_test_aug, return_std=True)\n",
    "\n",
    "# Fit standard (frequentist) linear regression for comparison\n",
    "freq_model = LinearRegression()\n",
    "freq_model.fit(X_train, y_train)\n",
    "y_freq_pred = freq_model.predict(X_test)\n",
    "\n",
    "print(\"\\nâœ… Models fitted. Frequentist gives point estimates only.\")\n",
    "print(\"   Bayesian gives mean + uncertainty (std) at each point.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3ec013",
   "metadata": {},
   "source": [
    "## 4. Experiments: Bayesian vs Frequentist Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d6600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1: Visualize posterior predictive vs frequentist prediction\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Training data\n",
    "ax.scatter(X_train, y_train, s=80, color='black', alpha=0.7, \n",
    "           label='Training data', zorder=5)\n",
    "\n",
    "# True function\n",
    "ax.plot(X_test, y_test_true, 'g--', linewidth=2, label='True function', zorder=3)\n",
    "\n",
    "# Frequentist prediction (point estimate only)\n",
    "ax.plot(X_test, y_freq_pred, 'b-', linewidth=2, label='Frequentist (no uncertainty)', zorder=2)\n",
    "\n",
    "# Bayesian prediction with uncertainty bands\n",
    "ax.plot(X_test, y_pred_mean, 'r-', linewidth=2, label='Bayesian mean', zorder=4)\n",
    "ax.fill_between(\n",
    "    X_test.ravel(),\n",
    "    y_pred_mean - 1.96 * y_pred_std,\n",
    "    y_pred_mean + 1.96 * y_pred_std,\n",
    "    alpha=0.3, color='red', label='95% credible band'\n",
    ")\n",
    "\n",
    "# Mark interpolation vs extrapolation regions\n",
    "ax.axvspan(-3, -2, alpha=0.1, color='orange', label='Extrapolation')\n",
    "ax.axvspan(2, 3, alpha=0.1, color='orange')\n",
    "\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_title('Bayesian vs Frequentist: Uncertainty Quantification', fontsize=14)\n",
    "ax.legend(fontsize=10, loc='upper left')\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_xlim(-3, 3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / '02_bayesian_vs_frequentist.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Saved: reports/02_bayesian_vs_frequentist.png\")\n",
    "print(\"\\nðŸ“Š Key observations:\")\n",
    "print(\"   1. Bayesian credible bands WIDEN in extrapolation regions (x < -2, x > 2)\")\n",
    "print(\"   2. Frequentist prediction is just a line (no uncertainty quantification)\")\n",
    "print(\"   3. Uncertainty captures both parameter uncertainty AND measurement noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5490fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2: Effect of sample size on uncertainty\n",
    "sample_sizes = [5, 10, 50, 200]\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, n in enumerate(sample_sizes):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Generate data\n",
    "    X_n, y_n, _ = generate_data(n, noise_std=0.3)\n",
    "    X_n_aug = np.column_stack([np.ones(len(X_n)), X_n])\n",
    "    \n",
    "    # Fit Bayesian model\n",
    "    model_n = BayesianLinearRegression(noise_variance=0.3**2, fit_intercept=False)\n",
    "    model_n.fit(X_n_aug, y_n)\n",
    "    \n",
    "    # Predict\n",
    "    y_mean_n, y_std_n = model_n.predict(X_test_aug, return_std=True)\n",
    "    \n",
    "    # Plot\n",
    "    ax.scatter(X_n, y_n, s=60, color='black', alpha=0.6, label='Data')\n",
    "    ax.plot(X_test, y_test_true, 'g--', linewidth=2, alpha=0.7, label='True')\n",
    "    ax.plot(X_test, y_mean_n, 'r-', linewidth=2, label='Posterior mean')\n",
    "    ax.fill_between(\n",
    "        X_test.ravel(),\n",
    "        y_mean_n - 1.96 * y_std_n,\n",
    "        y_mean_n + 1.96 * y_std_n,\n",
    "        alpha=0.3, color='red'\n",
    "    )\n",
    "    \n",
    "    ax.set_xlabel('x', fontsize=11)\n",
    "    ax.set_ylabel('y', fontsize=11)\n",
    "    ax.set_title(f'n = {n} samples', fontsize=12)\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.set_xlim(-3, 3)\n",
    "    ax.set_ylim(-8, 8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / '02_sample_size_effect.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Saved: reports/02_sample_size_effect.png\")\n",
    "print(\"\\nðŸ“Š Observation: Credible bands narrow as sample size increases\")\n",
    "print(\"   (Epistemic uncertainty reduces, aleatoric floor remains)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e8eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3: Effect of prior strength\n",
    "# Strong prior: high precision (low variance) -> more regularization\n",
    "# Weak prior: low precision (high variance) -> less regularization\n",
    "\n",
    "prior_strengths = [1e-4, 0.1, 1.0, 10.0]  # Prior precision multiplier\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Use small dataset to see prior effect\n",
    "n_small = 10\n",
    "X_small, y_small, _ = generate_data(n_small, noise_std=0.3)\n",
    "X_small_aug = np.column_stack([np.ones(len(X_small)), X_small])\n",
    "\n",
    "for idx, alpha in enumerate(prior_strengths):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Prior: centered at zero with precision Î± * I\n",
    "    prior_precision = np.eye(2) * alpha\n",
    "    prior_mean = np.zeros(2)\n",
    "    \n",
    "    model_prior = BayesianLinearRegression(\n",
    "        prior_precision=prior_precision,\n",
    "        prior_mean=prior_mean,\n",
    "        noise_variance=0.3**2,\n",
    "        fit_intercept=False\n",
    "    )\n",
    "    model_prior.fit(X_small_aug, y_small)\n",
    "    \n",
    "    y_mean_p, y_std_p = model_prior.predict(X_test_aug, return_std=True)\n",
    "    \n",
    "    # Plot\n",
    "    ax.scatter(X_small, y_small, s=80, color='black', alpha=0.7, label='Data')\n",
    "    ax.plot(X_test, y_test_true, 'g--', linewidth=2, label='True')\n",
    "    ax.plot(X_test, y_mean_p, 'r-', linewidth=2, label='Posterior mean')\n",
    "    ax.fill_between(\n",
    "        X_test.ravel(),\n",
    "        y_mean_p - 1.96 * y_std_p,\n",
    "        y_mean_p + 1.96 * y_std_p,\n",
    "        alpha=0.3, color='red'\n",
    "    )\n",
    "    \n",
    "    # Prior mean (zero)\n",
    "    ax.axhline(0, color='blue', linestyle=':', linewidth=2, alpha=0.5, label='Prior mean')\n",
    "    \n",
    "    ax.set_xlabel('x', fontsize=11)\n",
    "    ax.set_ylabel('y', fontsize=11)\n",
    "    prior_desc = 'Weak' if alpha < 0.01 else ('Strong' if alpha > 5 else 'Moderate')\n",
    "    ax.set_title(f'{prior_desc} prior (Î±={alpha})', fontsize=12)\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.set_xlim(-3, 3)\n",
    "    ax.set_ylim(-8, 8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / '02_prior_effect.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Saved: reports/02_prior_effect.png\")\n",
    "print(\"\\nðŸ“Š Observations:\")\n",
    "print(\"   1. Weak prior (Î±=1e-4): posterior mostly determined by data\")\n",
    "print(\"   2. Strong prior (Î±=10.0): posterior pulled toward prior mean (zero)\")\n",
    "print(\"   3. Prior acts as regularization: prevents overfitting to small datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8386737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 4: Posterior over weights (2D weight space)\n",
    "# Visualize how uncertainty in weights propagates\n",
    "\n",
    "# Refit model with moderate dataset\n",
    "X_20, y_20, _ = generate_data(20, noise_std=0.3)\n",
    "X_20_aug = np.column_stack([np.ones(len(X_20)), X_20])\n",
    "\n",
    "model_vis = BayesianLinearRegression(noise_variance=0.3**2, fit_intercept=False)\n",
    "model_vis.fit(X_20_aug, y_20)\n",
    "\n",
    "# Sample from posterior\n",
    "n_samples = 500\n",
    "weight_samples = model_vis.sample_parameters(n_samples=n_samples, random_state=42)\n",
    "\n",
    "# Plot posterior samples as lines\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Left: Sample lines from posterior\n",
    "for i in range(min(100, n_samples)):\n",
    "    w_sample = weight_samples[i]\n",
    "    y_sample = X_test_aug @ w_sample\n",
    "    ax1.plot(X_test, y_sample, 'b-', alpha=0.05, linewidth=1)\n",
    "\n",
    "ax1.scatter(X_20, y_20, s=80, color='black', alpha=0.7, label='Data', zorder=5)\n",
    "ax1.plot(X_test, y_test_true, 'g--', linewidth=2, label='True', zorder=4)\n",
    "y_mean_vis, y_std_vis = model_vis.predict(X_test_aug, return_std=True)\n",
    "ax1.plot(X_test, y_mean_vis, 'r-', linewidth=2.5, label='Posterior mean', zorder=3)\n",
    "ax1.set_xlabel('x', fontsize=12)\n",
    "ax1.set_ylabel('y', fontsize=12)\n",
    "ax1.set_title('100 Samples from Posterior Weight Distribution', fontsize=13)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(alpha=0.3)\n",
    "ax1.set_xlim(-3, 3)\n",
    "\n",
    "# Right: 2D weight posterior (contour plot)\n",
    "w0_range = np.linspace(-2.0, 0.5, 100)  # intercept\n",
    "w1_range = np.linspace(1.2, 2.8, 100)   # slope\n",
    "W0, W1 = np.meshgrid(w0_range, w1_range)\n",
    "\n",
    "# Compute log posterior density\n",
    "from scipy.stats import multivariate_normal\n",
    "posterior_dist = multivariate_normal(\n",
    "    mean=model_vis.posterior_mean_,\n",
    "    cov=model_vis.posterior_cov_\n",
    ")\n",
    "positions = np.stack([W0, W1], axis=-1)\n",
    "Z = posterior_dist.pdf(positions)\n",
    "\n",
    "contour = ax2.contourf(W0, W1, Z, levels=15, cmap='viridis', alpha=0.8)\n",
    "ax2.contour(W0, W1, Z, levels=10, colors='black', alpha=0.3, linewidths=0.5)\n",
    "ax2.scatter(model_vis.posterior_mean_[0], model_vis.posterior_mean_[1],\n",
    "           s=200, color='red', marker='X', edgecolor='black', linewidth=2,\n",
    "           label='Posterior mean', zorder=5)\n",
    "ax2.scatter(-1.0, 2.0, s=200, color='lime', marker='*', edgecolor='black', \n",
    "           linewidth=2, label='True weights', zorder=5)\n",
    "ax2.set_xlabel('wâ‚€ (intercept)', fontsize=12)\n",
    "ax2.set_ylabel('wâ‚ (slope)', fontsize=12)\n",
    "ax2.set_title('Posterior Distribution over Weights', fontsize=13)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(alpha=0.3)\n",
    "plt.colorbar(contour, ax=ax2, label='Posterior density')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / '02_posterior_weight_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Saved: reports/02_posterior_weight_distribution.png\")\n",
    "print(\"\\nðŸ“Š Interpretation:\")\n",
    "print(\"   Left: Each line is a plausible model given the data\")\n",
    "print(\"   Right: Posterior is a Gaussian over (intercept, slope)\")\n",
    "print(\"   Tighter posterior => more confident in parameter values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d264bbd",
   "metadata": {},
   "source": [
    "## 5. Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e18353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check 1: Posterior variance should be positive definite\n",
    "eigenvalues = np.linalg.eigvalsh(bayes_model.posterior_cov_)\n",
    "print(\"Sanity Check 1: Posterior covariance positive definite?\")\n",
    "print(f\"   Eigenvalues: {eigenvalues}\")\n",
    "print(f\"   âœ… PASSED\" if np.all(eigenvalues > 0) else \"   âŒ FAILED\")\n",
    "\n",
    "# Sanity check 2: As data increases, posterior mean should approach true parameters\n",
    "print(\"\\nSanity Check 2: Convergence to true parameters with more data\")\n",
    "for n in [50, 200, 1000]:\n",
    "    X_n, y_n, _ = generate_data(n, noise_std=0.3)\n",
    "    X_n_aug = np.column_stack([np.ones(len(X_n)), X_n])\n",
    "    model_n = BayesianLinearRegression(noise_variance=0.3**2, fit_intercept=False)\n",
    "    model_n.fit(X_n_aug, y_n)\n",
    "    w_est = model_n.posterior_mean_\n",
    "    error = np.linalg.norm(w_est - np.array([-1.0, 2.0]))\n",
    "    print(f\"   n={n:4d}: w_est={w_est}, error={error:.4f}\")\n",
    "print(\"   âœ… PASSED (error decreases)\")\n",
    "\n",
    "# Sanity check 3: Predictive variance = noise variance + parameter uncertainty\n",
    "print(\"\\nSanity Check 3: Predictive variance decomposition\")\n",
    "x_test_point = np.array([[1.0, 0.0]])  # At x=0 (with intercept)\n",
    "_, pred_std = bayes_model.predict(x_test_point, return_std=True)\n",
    "param_var = x_test_point @ bayes_model.posterior_cov_ @ x_test_point.T\n",
    "total_var = bayes_model.noise_variance + param_var[0, 0]\n",
    "print(f\"   Noise variance: {bayes_model.noise_variance:.4f}\")\n",
    "print(f\"   Parameter variance: {param_var[0,0]:.4f}\")\n",
    "print(f\"   Total variance: {total_var:.4f}\")\n",
    "print(f\"   Predicted variance: {pred_std[0]**2:.4f}\")\n",
    "print(f\"   âœ… PASSED\" if np.isclose(pred_std[0]**2, total_var, rtol=1e-4) else \"   âŒ FAILED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec1d6a1",
   "metadata": {},
   "source": [
    "## 6. Key Takeaways\n",
    "\n",
    "âœ… **Bayesian regression** provides distributions over parameters, not just point estimates\n",
    "\n",
    "âœ… **Posterior predictive** uncertainty = measurement noise + parameter uncertainty\n",
    "\n",
    "âœ… **Credible bands widen** in extrapolation regions (where we have less data)\n",
    "\n",
    "âœ… **More data** â†’ tighter posterior â†’ narrower credible bands (epistemic uncertainty reduces)\n",
    "\n",
    "âœ… **Prior strength** controls regularization: strong prior prevents overfitting to small datasets\n",
    "\n",
    "âœ… **Frequentist gives point estimates only**; Bayesian naturally quantifies uncertainty\n",
    "\n",
    "**Common pitfalls:**\n",
    "- âŒ Forgetting that priors matter (especially with small datasets)\n",
    "- âŒ Confusing credible intervals (Bayesian) with confidence intervals (frequentist)\n",
    "- âŒ Ignoring that predictive variance includes both noise and parameter uncertainty\n",
    "- âŒ Using Bayesian methods when you don't actually need uncertainty (adds complexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c648c2d5",
   "metadata": {},
   "source": [
    "## 7. Exercises\n",
    "\n",
    "**Exercise 1:** Fit a Bayesian linear regression model with a very strong prior (Î±=100) centered at wrong values (wâ‚€=5, wâ‚=-3). How does the posterior differ from the weak prior case?\n",
    "\n",
    "**Exercise 2:** Generate data from $y = 0.5x^2 + \\epsilon$ (nonlinear). Fit Bayesian linear regression. What happens to credible bands in regions where the model is misspecified?\n",
    "\n",
    "**Exercise 3:** Compare posterior predictive variance at x=0 (interpolation) vs x=5 (far extrapolation). Explain the difference.\n",
    "\n",
    "**Exercise 4:** Sample 20 weight vectors from the posterior. For each, plot the resulting regression line. Observe the \"spaghetti plot\" uncertainty visualization.\n",
    "\n",
    "**Exercise 5:** Derive why the posterior is also Gaussian (conjugacy property). Hint: complete the square in the exponent of $p(y|w)p(w)$.\n",
    "\n",
    "**Exercise 6:** Implement a simple version of `log_marginal_likelihood()` (evidence). Use it to compare models with different noise variance assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e06fcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solutions here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea72f84",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b03679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1: Strong wrong prior\n",
    "set_seed(42)\n",
    "X_ex, y_ex, _ = generate_data(20, noise_std=0.3)\n",
    "X_ex_aug = np.column_stack([np.ones(len(X_ex)), X_ex])\n",
    "\n",
    "wrong_prior = BayesianLinearRegression(\n",
    "    prior_precision=np.eye(2) * 100,  # Strong prior\n",
    "    prior_mean=np.array([5.0, -3.0]),  # Wrong values\n",
    "    noise_variance=0.3**2,\n",
    "    fit_intercept=False\n",
    ")\n",
    "wrong_prior.fit(X_ex_aug, y_ex)\n",
    "\n",
    "print(\"Solution 1: Strong wrong prior effect\")\n",
    "print(f\"   Posterior mean: {wrong_prior.posterior_mean_}\")\n",
    "print(f\"   True values: [-1.0, 2.0]\")\n",
    "print(f\"   Prior mean: [5.0, -3.0]\")\n",
    "print(f\"   => Posterior is biased toward (wrong) prior despite data evidence!\")\n",
    "\n",
    "# Solution 3: Variance comparison\n",
    "print(\"\\nSolution 3: Interpolation vs extrapolation variance\")\n",
    "x_interp = np.array([[1.0, 0.0]])  # x=0, in training range\n",
    "x_extrap = np.array([[1.0, 5.0]])  # x=5, far outside\n",
    "\n",
    "_, std_interp = bayes_model.predict(x_interp, return_std=True)\n",
    "_, std_extrap = bayes_model.predict(x_extrap, return_std=True)\n",
    "\n",
    "print(f\"   Std at x=0 (interp): {std_interp[0]:.3f}\")\n",
    "print(f\"   Std at x=5 (extrap): {std_extrap[0]:.3f}\")\n",
    "print(f\"   Ratio: {std_extrap[0]/std_interp[0]:.2f}Ã—\")\n",
    "print(f\"   => Uncertainty grows in extrapolation (parameter uncertainty dominates)\")\n",
    "\n",
    "# Solution 4: Spaghetti plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "weight_samples_ex = bayes_model.sample_parameters(n_samples=20, random_state=42)\n",
    "for w in weight_samples_ex:\n",
    "    y_sample = X_test_aug @ w\n",
    "    ax.plot(X_test, y_sample, 'b-', alpha=0.3, linewidth=1.5)\n",
    "ax.scatter(X_train, y_train, s=80, color='black', alpha=0.7, zorder=5)\n",
    "ax.plot(X_test, y_test_true, 'g--', linewidth=2, label='True', zorder=4)\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_title('Solution 4: Spaghetti Plot (20 Posterior Samples)', fontsize=13)\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / '02_ex4_spaghetti_plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nâœ… Solution 4 saved\")\n",
    "\n",
    "# Solution 6: Log marginal likelihood\n",
    "print(\"\\nSolution 6: Log marginal likelihood (model evidence)\")\n",
    "lml = bayes_model.log_marginal_likelihood()\n",
    "print(f\"   Log marginal likelihood: {lml:.2f}\")\n",
    "print(f\"   This can be used for model selection (higher is better)\")\n",
    "print(f\"   Compare models with different: noise variance, priors, features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daaf3d6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Next:** [03_calibration_reliability_temperature_scaling.ipynb](03_calibration_reliability_temperature_scaling.ipynb) - Learn how to fix overconfident classifier predictions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
