{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bae4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add repo root to path for imports\n",
    "repo_root = Path().resolve().parents[2]\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "from modules._import_helper import safe_import_from\n",
    "\n",
    "# Import seeding utilities\n",
    "set_seed = safe_import_from('00_repo_standards.src.mlphys_core.seeding', 'set_seed')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Create reports directory\n",
    "reports_dir = Path(\"../reports\")\n",
    "reports_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014c4575",
   "metadata": {},
   "source": [
    "## 1. Intuition: Uncertainty in Physics Measurements\n",
    "\n",
    "**Key concepts:**\n",
    "- **Measurement noise**: When you measure a physical quantity (temperature, voltage, position), you never get the exact \"true\" value\n",
    "- **Repeated measurements** reveal the distribution of possible values\n",
    "- **Two types of uncertainty**:\n",
    "  - **Aleatoric (irreducible)**: Inherent randomness in the measurement process (e.g., thermal noise in sensors)\n",
    "  - **Epistemic (reducible)**: Uncertainty due to lack of knowledge (e.g., uncertain model parameters, insufficient data)\n",
    "- In physics labs, we report: $\\mu \\pm \\sigma$ (mean ¬± standard error)\n",
    "- This notebook shows how to quantify and visualize both types\n",
    "\n",
    "**Physics analogy**: Measuring the decay time of a particle:\n",
    "- Aleatoric: Each particle's decay is inherently random\n",
    "- Epistemic: With more measurements, we better estimate the mean decay time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c0aa1",
   "metadata": {},
   "source": [
    "## 2. Minimal Math: Sampling Distribution\n",
    "\n",
    "**Setup:**\n",
    "- True (unknown) parameter: $\\theta_{\\text{true}}$\n",
    "- Noisy measurements: $x_i = \\theta_{\\text{true}} + \\epsilon_i$, where $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$\n",
    "- Sample mean estimator: $\\hat{\\theta} = \\frac{1}{n}\\sum_{i=1}^n x_i$\n",
    "\n",
    "**Key results:**\n",
    "1. **Expectation**: $\\mathbb{E}[\\hat{\\theta}] = \\theta_{\\text{true}}$ (unbiased)\n",
    "2. **Variance**: $\\text{Var}(\\hat{\\theta}) = \\frac{\\sigma^2}{n}$ (decreases with more data!)\n",
    "3. **Central Limit Theorem**: $\\hat{\\theta} \\sim \\mathcal{N}\\left(\\theta_{\\text{true}}, \\frac{\\sigma^2}{n}\\right)$ for large $n$\n",
    "\n",
    "**Interpretation:**\n",
    "- $\\sigma$ = aleatoric uncertainty (measurement noise)\n",
    "- $\\sigma / \\sqrt{n}$ = epistemic uncertainty (standard error of the mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595033f5",
   "metadata": {},
   "source": [
    "## 3. Implementation: Repeated Measurements Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e59cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate measuring a physical constant (e.g., decay time in seconds)\n",
    "true_value = 5.0  # True parameter we're trying to measure\n",
    "measurement_noise = 1.5  # Standard deviation of measurement error (aleatoric)\n",
    "\n",
    "def make_measurement(n_measurements: int) -> np.ndarray:\n",
    "    \"\"\"Simulate n noisy measurements of the true value.\"\"\"\n",
    "    noise = np.random.normal(0, measurement_noise, size=n_measurements)\n",
    "    return true_value + noise\n",
    "\n",
    "# Take measurements with different sample sizes\n",
    "sample_sizes = [5, 20, 100, 500]\n",
    "measurements_dict = {n: make_measurement(n) for n in sample_sizes}\n",
    "\n",
    "# Compute estimates and uncertainties\n",
    "results = {}\n",
    "for n, measurements in measurements_dict.items():\n",
    "    mean_estimate = np.mean(measurements)\n",
    "    std_error = np.std(measurements, ddof=1) / np.sqrt(n)  # Standard error\n",
    "    results[n] = {\n",
    "        'mean': mean_estimate,\n",
    "        'sem': std_error,\n",
    "        'measurements': measurements\n",
    "    }\n",
    "    print(f\"n={n:3d}: Œ∏ÃÇ = {mean_estimate:.3f} ¬± {std_error:.3f} (true: {true_value:.3f})\")\n",
    "\n",
    "print(f\"\\n‚úÖ Notice: Standard error decreases as ‚àön (epistemic uncertainty reduces)\")\n",
    "print(f\"   But individual measurements still vary by ~{measurement_noise:.2f} (aleatoric)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aaf2bf",
   "metadata": {},
   "source": [
    "## 4. Experiments: Visualizing Uncertainty Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d2b5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1: Show sampling distributions for different sample sizes\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, n in enumerate(sample_sizes):\n",
    "    ax = axes[idx]\n",
    "    measurements = results[n]['measurements']\n",
    "    mean_est = results[n]['mean']\n",
    "    sem = results[n]['sem']\n",
    "    \n",
    "    # Histogram of measurements\n",
    "    ax.hist(measurements, bins=20, alpha=0.6, color='steelblue', \n",
    "            edgecolor='black', density=True, label='Measurements')\n",
    "    \n",
    "    # True distribution overlay\n",
    "    x_range = np.linspace(measurements.min() - 1, measurements.max() + 1, 200)\n",
    "    true_dist = (1 / (measurement_noise * np.sqrt(2*np.pi))) * \\\n",
    "                np.exp(-0.5 * ((x_range - true_value) / measurement_noise)**2)\n",
    "    ax.plot(x_range, true_dist, 'k--', linewidth=2, label=f'True dist (œÉ={measurement_noise})')\n",
    "    \n",
    "    # Mark true value and estimate\n",
    "    ax.axvline(true_value, color='green', linewidth=2, label='True value')\n",
    "    ax.axvline(mean_est, color='red', linewidth=2, label=f'Estimate ¬± SE')\n",
    "    ax.axvspan(mean_est - 1.96*sem, mean_est + 1.96*sem, \n",
    "               alpha=0.2, color='red', label='95% CI')\n",
    "    \n",
    "    ax.set_xlabel('Measurement value')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title(f'n = {n} measurements\\n'\n",
    "                 f'Estimate: {mean_est:.2f} ¬± {sem:.3f}')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / '01_sampling_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Saved: reports/01_sampling_distributions.png\")\n",
    "print(\"\\nüìä Observation: As n increases, the estimate gets closer to true value\")\n",
    "print(\"   and the confidence interval (red band) narrows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0543d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2: Standard Error vs Sample Size (epistemic uncertainty reduction)\n",
    "n_range = np.arange(5, 501, 5)\n",
    "standard_errors = []\n",
    "\n",
    "# Run many experiments to get empirical SEM\n",
    "n_experiments = 100\n",
    "for n in n_range:\n",
    "    estimates = [np.mean(make_measurement(n)) for _ in range(n_experiments)]\n",
    "    standard_errors.append(np.std(estimates))\n",
    "\n",
    "# Theoretical prediction: œÉ / ‚àön\n",
    "theoretical_sem = measurement_noise / np.sqrt(n_range)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(n_range, standard_errors, 'o', markersize=4, alpha=0.6, \n",
    "        label='Empirical SEM (100 trials)')\n",
    "ax.plot(n_range, theoretical_sem, 'r-', linewidth=2, \n",
    "        label=r'Theoretical: $\\sigma / \\sqrt{n}$')\n",
    "ax.set_xlabel('Sample size (n)', fontsize=12)\n",
    "ax.set_ylabel('Standard Error of Mean (SEM)', fontsize=12)\n",
    "ax.set_title('Epistemic Uncertainty Decreases with More Data', fontsize=14)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_xlim(0, 500)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / '01_epistemic_uncertainty_reduction.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Saved: reports/01_epistemic_uncertainty_reduction.png\")\n",
    "print(\"\\nüìä Key insight: Epistemic uncertainty (SEM) ‚àù 1/‚àön\")\n",
    "print(\"   To halve your uncertainty, you need 4√ó more data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e08ef5",
   "metadata": {},
   "source": [
    "## 5. Confidence Intervals vs Credible Intervals\n",
    "\n",
    "**Two philosophies for quantifying uncertainty:**\n",
    "\n",
    "### Frequentist Confidence Interval (CI)\n",
    "- **Interpretation**: \"If we repeated this experiment many times, 95% of constructed intervals would contain the true value\"\n",
    "- **The parameter is fixed**, the interval is random (changes with each dataset)\n",
    "- Example: $\\hat{\\theta} \\pm 1.96 \\cdot \\text{SE}$ (assumes normal distribution)\n",
    "\n",
    "### Bayesian Credible Interval\n",
    "- **Interpretation**: \"There is a 95% probability that the true value lies in this interval\"\n",
    "- **The interval is fixed** (for a given dataset), the parameter has a probability distribution\n",
    "- Requires: prior belief about $\\theta$ + Bayes' rule to get posterior\n",
    "- More natural for \"degree of belief\" statements\n",
    "\n",
    "**When they agree:** With flat priors and lots of data, Bayesian credible intervals ‚âà frequentist CIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded888d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check: Verify CI coverage\n",
    "# If we construct 95% CIs many times, ~95% should contain the true value\n",
    "\n",
    "n_samples = 50\n",
    "n_experiments = 1000\n",
    "coverage_count = 0\n",
    "\n",
    "ci_lower_bounds = []\n",
    "ci_upper_bounds = []\n",
    "\n",
    "for _ in range(n_experiments):\n",
    "    measurements = make_measurement(n_samples)\n",
    "    mean_est = np.mean(measurements)\n",
    "    sem = np.std(measurements, ddof=1) / np.sqrt(n_samples)\n",
    "    \n",
    "    # 95% CI (assumes normal distribution)\n",
    "    ci_lower = mean_est - 1.96 * sem\n",
    "    ci_upper = mean_est + 1.96 * sem\n",
    "    \n",
    "    ci_lower_bounds.append(ci_lower)\n",
    "    ci_upper_bounds.append(ci_upper)\n",
    "    \n",
    "    # Check if interval contains true value\n",
    "    if ci_lower <= true_value <= ci_upper:\n",
    "        coverage_count += 1\n",
    "\n",
    "coverage_rate = coverage_count / n_experiments\n",
    "print(f\"Empirical CI coverage: {coverage_rate:.1%} (expected: ~95%)\")\n",
    "print(f\"‚úÖ SANITY CHECK {'PASSED' if 0.94 <= coverage_rate <= 0.96 else 'WARNING'}\")\n",
    "\n",
    "# Visualize a few confidence intervals\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "n_show = 50\n",
    "colors = ['green' if ci_lower_bounds[i] <= true_value <= ci_upper_bounds[i] \n",
    "          else 'red' for i in range(n_show)]\n",
    "\n",
    "for i in range(n_show):\n",
    "    ax.plot([ci_lower_bounds[i], ci_upper_bounds[i]], [i, i], \n",
    "            color=colors[i], linewidth=1.5, alpha=0.7)\n",
    "    \n",
    "ax.axvline(true_value, color='blue', linewidth=2, linestyle='--', \n",
    "           label=f'True value = {true_value}')\n",
    "ax.set_xlabel('Parameter value', fontsize=12)\n",
    "ax.set_ylabel('Experiment number', fontsize=12)\n",
    "ax.set_title(f'50 Confidence Intervals (n={n_samples} each)\\n'\n",
    "             f'Green: Contains true value | Red: Misses true value', fontsize=13)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / '01_confidence_intervals_coverage.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Saved: reports/01_confidence_intervals_coverage.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb5913a",
   "metadata": {},
   "source": [
    "## 6. Key Takeaways\n",
    "\n",
    "‚úÖ **Two types of uncertainty:**\n",
    "- **Aleatoric**: Irreducible randomness (measurement noise, $\\sigma$)\n",
    "- **Epistemic**: Reducible with more data (parameter uncertainty, $\\sigma/\\sqrt{n}$)\n",
    "\n",
    "‚úÖ **Standard error of the mean** ($\\text{SEM} = \\sigma/\\sqrt{n}$) quantifies epistemic uncertainty\n",
    "\n",
    "‚úÖ **Confidence intervals**:\n",
    "- Frequentist: 95% of repeated experiments contain true value\n",
    "- Bayesian credible: 95% probability true value is in interval (see Notebook 02)\n",
    "\n",
    "‚úÖ **More data reduces epistemic uncertainty**, but aleatoric uncertainty remains\n",
    "\n",
    "**Common pitfalls:**\n",
    "- ‚ùå Confusing $\\sigma$ (data spread) with $\\text{SEM}$ (estimate uncertainty)\n",
    "- ‚ùå Thinking \"95% CI\" means \"95% chance true value is here\" (that's Bayesian!)\n",
    "- ‚ùå Ignoring finite-sample corrections (use $t$-distribution for small $n$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d46057",
   "metadata": {},
   "source": [
    "## 7. Exercises\n",
    "\n",
    "**Exercise 1:** What sample size $n$ is needed to achieve $\\text{SEM} \\leq 0.1$ if $\\sigma = 2.0$?\n",
    "\n",
    "**Exercise 2:** If you have $n=25$ measurements with $\\bar{x} = 10.5$ and $s = 2.0$, compute the 95% confidence interval for the mean.\n",
    "\n",
    "**Exercise 3:** Simulate 1000 experiments where you estimate a mean from $n=10$ samples. What fraction of 95% CIs contain the true mean?\n",
    "\n",
    "**Exercise 4:** Generate data where aleatoric uncertainty is high ($\\sigma=5$) and another where it's low ($\\sigma=0.5$). For each, plot how epistemic uncertainty changes with $n \\in [10, 100]$.\n",
    "\n",
    "**Exercise 5:** Explain why $\\text{SEM} \\propto 1/\\sqrt{n}$ means you get \"diminishing returns\" from collecting more data.\n",
    "\n",
    "**Exercise 6:** Research: What is the $t$-distribution and when should you use $t_{n-1}$ critical values instead of $1.96$ for confidence intervals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a809fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solutions here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115f3850",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3b0e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1: SEM = œÉ/‚àön ‚â§ 0.1  =>  n ‚â• (œÉ/0.1)^2\n",
    "sigma = 2.0\n",
    "target_sem = 0.1\n",
    "n_needed = (sigma / target_sem)**2\n",
    "print(f\"Solution 1: n ‚â• {n_needed:.0f} samples needed\")\n",
    "print(f\"   (Verify: SEM at n={n_needed:.0f} is {sigma/np.sqrt(n_needed):.3f})\")\n",
    "\n",
    "# Solution 2: 95% CI using t-distribution (small sample)\n",
    "from scipy import stats\n",
    "n = 25\n",
    "mean = 10.5\n",
    "std = 2.0\n",
    "sem = std / np.sqrt(n)\n",
    "t_critical = stats.t.ppf(0.975, df=n-1)  # 2-tailed, df=n-1\n",
    "ci_lower = mean - t_critical * sem\n",
    "ci_upper = mean + t_critical * sem\n",
    "print(f\"\\nSolution 2: 95% CI = [{ci_lower:.2f}, {ci_upper:.2f}]\")\n",
    "print(f\"   (Using t-critical = {t_critical:.3f} for df={n-1})\")\n",
    "\n",
    "# Solution 3: Empirical coverage\n",
    "set_seed(42)\n",
    "true_param = 10.0\n",
    "sigma = 2.0\n",
    "n_exp = 1000\n",
    "n_samples = 10\n",
    "coverage = 0\n",
    "for _ in range(n_exp):\n",
    "    data = np.random.normal(true_param, sigma, size=n_samples)\n",
    "    mean_est = np.mean(data)\n",
    "    sem = np.std(data, ddof=1) / np.sqrt(n_samples)\n",
    "    t_crit = stats.t.ppf(0.975, df=n_samples-1)\n",
    "    ci_low = mean_est - t_crit * sem\n",
    "    ci_high = mean_est + t_crit * sem\n",
    "    if ci_low <= true_param <= ci_high:\n",
    "        coverage += 1\n",
    "print(f\"\\nSolution 3: Coverage = {coverage/n_exp:.1%} (expected ~95%)\")\n",
    "\n",
    "# Solution 4: Compare high vs low aleatoric uncertainty\n",
    "set_seed(42)\n",
    "n_range = np.arange(10, 101, 5)\n",
    "sigma_high = 5.0\n",
    "sigma_low = 0.5\n",
    "\n",
    "sem_high = [sigma_high / np.sqrt(n) for n in n_range]\n",
    "sem_low = [sigma_low / np.sqrt(n) for n in n_range]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(n_range, sem_high, 'o-', label=f'High aleatoric (œÉ={sigma_high})', linewidth=2)\n",
    "ax.plot(n_range, sem_low, 's-', label=f'Low aleatoric (œÉ={sigma_low})', linewidth=2)\n",
    "ax.set_xlabel('Sample size (n)', fontsize=12)\n",
    "ax.set_ylabel('Epistemic uncertainty (SEM)', fontsize=12)\n",
    "ax.set_title('Solution 4: Epistemic Uncertainty vs Sample Size', fontsize=13)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / '01_ex4_uncertainty_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\n‚úÖ Solution 4 plot saved\")\n",
    "\n",
    "# Solution 5: Explanation\n",
    "print(\"\\nSolution 5: Diminishing returns explanation:\")\n",
    "print(\"   To reduce SEM from 1.0 to 0.5 (50% reduction): need 4√ó more data\")\n",
    "print(\"   To reduce SEM from 0.5 to 0.25 (another 50%): need another 4√ó (16√ó total)\")\n",
    "print(\"   Each additional doubling of precision requires 4√ó more effort!\")\n",
    "\n",
    "# Solution 6: t-distribution\n",
    "print(\"\\nSolution 6: t-distribution usage:\")\n",
    "print(\"   Use t-distribution when:\")\n",
    "print(\"   - Sample size is small (n < 30 rule of thumb)\")\n",
    "print(\"   - Population œÉ is unknown (estimated from sample)\")\n",
    "print(\"   - Accounts for extra uncertainty from estimating œÉ\")\n",
    "print(f\"   Example: n=10 => t_0.975,9 = {stats.t.ppf(0.975, 9):.3f} vs z_0.975 = 1.960\")\n",
    "print(f\"            n=100 => t_0.975,99 = {stats.t.ppf(0.975, 99):.3f} (approaches 1.96)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5134ddf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Next:** [02_bayesian_linear_regression_uq.ipynb](02_bayesian_linear_regression_uq.ipynb) - Learn how Bayesian methods naturally quantify parameter uncertainty"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
