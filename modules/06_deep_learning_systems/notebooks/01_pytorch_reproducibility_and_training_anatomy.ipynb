{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e44c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Add repo to path\n",
    "repo_root = Path.cwd().parent.parent.parent\n",
    "sys.path.insert(0, str(repo_root))\n",
    "\n",
    "from modules._import_helper import safe_import_from\n",
    "\n",
    "# Import module components\n",
    "TrainingConfig = safe_import_from('06_deep_learning_systems.src.config', 'TrainingConfig')\n",
    "SimpleMLP = safe_import_from('06_deep_learning_systems.src.models', 'SimpleMLP')\n",
    "get_mnist_loaders = safe_import_from('06_deep_learning_systems.src.datasets', 'get_mnist_loaders')\n",
    "Trainer = safe_import_from('06_deep_learning_systems.src.trainer', 'Trainer')\n",
    "set_seed = safe_import_from('00_repo_standards.src.mlphys_core.seeding', 'set_seed')\n",
    "\n",
    "print(\"‚úì All imports successful\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8132f8a8",
   "metadata": {},
   "source": [
    "## Part 1: Training Loop Anatomy\n",
    "\n",
    "A minimal training loop has these components:\n",
    "\n",
    "```python\n",
    "# 1. Data\n",
    "train_loader = DataLoader(train_dataset, ...)\n",
    "\n",
    "# 2. Model\n",
    "model = SimpleMLP(...)\n",
    "\n",
    "# 3. Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 4. Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# 5. Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        # Forward\n",
    "        output = model(batch_x)\n",
    "        loss = criterion(output, batch_y)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 6. Evaluation\n",
    "    val_loss, val_acc = evaluate(model, val_loader)\n",
    "```\n",
    "\n",
    "Our `Trainer` class encapsulates this pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e163c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup output directory\n",
    "reports_dir = Path(\"../reports/notebook_01\")\n",
    "reports_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Outputs will be saved to: {reports_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7dd4c7",
   "metadata": {},
   "source": [
    "## Part 2: Reproducibility - The Foundation\n",
    "\n",
    "**Question**: If I train the same model twice with the same code, will I get identical results?\n",
    "\n",
    "**Answer**: Only if you control all sources of randomness.\n",
    "\n",
    "### Sources of Randomness in PyTorch\n",
    "\n",
    "1. **Python** random module\n",
    "2. **NumPy** RNG\n",
    "3. **PyTorch CPU** RNG\n",
    "4. **PyTorch CUDA** RNG (if using GPU)\n",
    "5. **DataLoader** workers (multi-process)\n",
    "6. **Non-deterministic operations** (some GPU ops)\n",
    "\n",
    "Our `set_seed()` function handles the first 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f78506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_randomness():\n",
    "    \"\"\"Show what happens without setting seeds.\"\"\"\n",
    "    print(\"Without setting seed:\")\n",
    "    print(\"Run 1:\", torch.randn(3))\n",
    "    print(\"Run 2:\", torch.randn(3))\n",
    "    print(\"Run 3:\", torch.randn(3))\n",
    "    print(\"‚Üí Different every time!\\n\")\n",
    "    \n",
    "    print(\"With seed=42:\")\n",
    "    torch.manual_seed(42)\n",
    "    print(\"Run 1:\", torch.randn(3))\n",
    "    torch.manual_seed(42)\n",
    "    print(\"Run 2:\", torch.randn(3))\n",
    "    torch.manual_seed(42)\n",
    "    print(\"Run 3:\", torch.randn(3))\n",
    "    print(\"‚Üí Identical when seed is reset!\")\n",
    "\n",
    "demonstrate_randomness()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36365cd",
   "metadata": {},
   "source": [
    "## Part 3: Reproducible Training - Experiment 1\n",
    "\n",
    "Let's train a small model twice with the same seed and verify bit-identical results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ded866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_experiment(seed: int, name: str):\n",
    "    \"\"\"Run a training experiment with specified seed.\"\"\"\n",
    "    set_seed(seed)\n",
    "    \n",
    "    # Create config (small for speed)\n",
    "    config = TrainingConfig(\n",
    "        name=name,\n",
    "        seed=seed,\n",
    "        model_type=\"SimpleMLP\",\n",
    "        input_dim=784,\n",
    "        hidden_dims=[64, 32],\n",
    "        output_dim=10,\n",
    "        batch_size=128,\n",
    "        num_epochs=3,\n",
    "        learning_rate=1e-3,\n",
    "        early_stop_patience=10,  # No early stopping\n",
    "        save_artifacts=False,\n",
    "        device=\"cpu\",\n",
    "    )\n",
    "    \n",
    "    # Load data (small subset)\n",
    "    print(f\"\\n[{name}] Loading MNIST...\")\n",
    "    train_loader, val_loader, test_loader = get_mnist_loaders(\n",
    "        data_dir=Path(\"../../../data\"),\n",
    "        batch_size=config.batch_size,\n",
    "        val_split=0.1,\n",
    "        num_workers=0,  # No multiprocessing for reproducibility\n",
    "        seed=seed,\n",
    "    )\n",
    "    \n",
    "    # Create model\n",
    "    model = SimpleMLP(\n",
    "        input_dim=config.input_dim,\n",
    "        hidden_dims=config.hidden_dims,\n",
    "        output_dim=config.output_dim,\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    trainer = Trainer(config, model, device=\"cpu\")\n",
    "    history = trainer.train(train_loader, val_loader)\n",
    "    \n",
    "    # Evaluate\n",
    "    test_metrics = trainer.evaluate(test_loader)\n",
    "    \n",
    "    print(f\"[{name}] Final test accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "    \n",
    "    return history, test_metrics\n",
    "\n",
    "# Run experiment 1\n",
    "print(\"=\"*60)\n",
    "print(\"Experiment 1: First run with seed=42\")\n",
    "print(\"=\"*60)\n",
    "history1, metrics1 = run_training_experiment(seed=42, name=\"run1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ff2ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiment 2 (same seed)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Experiment 2: Second run with seed=42 (should be identical)\")\n",
    "print(\"=\"*60)\n",
    "history2, metrics2 = run_training_experiment(seed=42, name=\"run2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdbe6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify reproducibility\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Reproducibility Check\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compare final metrics\n",
    "print(\"\\nFinal Test Accuracy:\")\n",
    "print(f\"  Run 1: {metrics1['accuracy']:.6f}\")\n",
    "print(f\"  Run 2: {metrics2['accuracy']:.6f}\")\n",
    "print(f\"  Difference: {abs(metrics1['accuracy'] - metrics2['accuracy']):.10f}\")\n",
    "\n",
    "# Compare training histories\n",
    "train_loss_diff = np.array(history1['train_loss']) - np.array(history2['train_loss'])\n",
    "val_loss_diff = np.array(history1['val_loss']) - np.array(history2['val_loss'])\n",
    "\n",
    "print(\"\\nTraining History Differences:\")\n",
    "print(f\"  Train loss max diff: {np.abs(train_loss_diff).max():.10f}\")\n",
    "print(f\"  Val loss max diff: {np.abs(val_loss_diff).max():.10f}\")\n",
    "\n",
    "if np.allclose(history1['train_loss'], history2['train_loss'], atol=1e-6):\n",
    "    print(\"\\n‚úÖ REPRODUCIBLE: Results are bit-identical (within 1e-6)\")\n",
    "else:\n",
    "    print(\"\\n‚ùå NOT REPRODUCIBLE: Results differ!\")\n",
    "    print(\"   This could be due to:\")\n",
    "    print(\"   - GPU non-determinism\")\n",
    "    print(\"   - DataLoader workers\")\n",
    "    print(\"   - Missing seed setting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab798270",
   "metadata": {},
   "source": [
    "## Part 4: Visualize Training Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81093f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "epochs = np.arange(1, len(history1['train_loss']) + 1)\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(epochs, history1['train_loss'], 'o-', label='Train Loss', linewidth=2, markersize=6)\n",
    "axes[0].plot(epochs, history1['val_loss'], 's-', label='Val Loss', linewidth=2, markersize=6)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Learning Curves (Reproducible Run)', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curve\n",
    "axes[1].plot(epochs, history1['val_accuracy'], 'o-', color='green', linewidth=2, markersize=6)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Validation Accuracy', fontsize=12)\n",
    "axes[1].set_title('Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / \"learning_curves.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úì Saved to {reports_dir / 'learning_curves.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05a04d4",
   "metadata": {},
   "source": [
    "## Part 5: Non-Determinism Demo\n",
    "\n",
    "Let's intentionally break reproducibility to understand what can go wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2997e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Demonstration: What breaks reproducibility?\\n\")\n",
    "\n",
    "# Case 1: Different seeds\n",
    "print(\"Case 1: Different seeds\")\n",
    "set_seed(42)\n",
    "result1 = torch.randn(3)\n",
    "set_seed(123)  # Different seed!\n",
    "result2 = torch.randn(3)\n",
    "print(f\"  Seed 42: {result1}\")\n",
    "print(f\"  Seed 123: {result2}\")\n",
    "print(f\"  ‚Üí Different results (as expected)\\n\")\n",
    "\n",
    "# Case 2: Forgot to set seed\n",
    "print(\"Case 2: Forgot to set seed before second run\")\n",
    "set_seed(42)\n",
    "result1 = torch.randn(3)\n",
    "# Forgot set_seed here!\n",
    "result2 = torch.randn(3)\n",
    "print(f\"  Run 1: {result1}\")\n",
    "print(f\"  Run 2: {result2}\")\n",
    "print(f\"  ‚Üí Non-reproducible!\\n\")\n",
    "\n",
    "# Case 3: GPU non-determinism (demonstration only)\n",
    "print(\"Case 3: GPU operations can be non-deterministic\")\n",
    "print(\"  Some CUDA ops use atomic operations that aren't deterministic\")\n",
    "print(\"  Solution: torch.use_deterministic_algorithms(True)\")\n",
    "print(\"  Trade-off: May be slower, some ops not supported\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ef4b57",
   "metadata": {},
   "source": [
    "## Part 6: Save Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5380e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "summary = {\n",
    "    \"experiment\": \"reproducibility_demo\",\n",
    "    \"seed\": 42,\n",
    "    \"num_epochs\": len(history1['train_loss']),\n",
    "    \"final_train_loss\": float(history1['train_loss'][-1]),\n",
    "    \"final_val_loss\": float(history1['val_loss'][-1]),\n",
    "    \"final_val_accuracy\": float(history1['val_accuracy'][-1]),\n",
    "    \"test_accuracy\": float(metrics1['accuracy']),\n",
    "    \"test_loss\": float(metrics1['loss']),\n",
    "    \"reproducibility_check\": {\n",
    "        \"run1_test_acc\": float(metrics1['accuracy']),\n",
    "        \"run2_test_acc\": float(metrics2['accuracy']),\n",
    "        \"difference\": float(abs(metrics1['accuracy'] - metrics2['accuracy'])),\n",
    "        \"is_reproducible\": bool(abs(metrics1['accuracy'] - metrics2['accuracy']) < 1e-6),\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(reports_dir / \"summary.json\", 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"‚úì Saved summary to {reports_dir / 'summary.json'}\")\n",
    "print(\"\\nSummary:\")\n",
    "print(json.dumps(summary, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369c2db6",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### ‚úÖ Best Practices\n",
    "\n",
    "1. **Always set seeds** at the start of experiments\n",
    "2. **Use CPU** for bit-identical reproducibility (GPU has non-deterministic ops)\n",
    "3. **Disable DataLoader workers** (`num_workers=0`) or set worker seed function\n",
    "4. **Log seeds** with experiments for reproducibility\n",
    "5. **Verify reproducibility** on small experiments before scaling up\n",
    "\n",
    "### ‚ö†Ô∏è Common Pitfalls\n",
    "\n",
    "1. **Forgetting to reset seed** between runs\n",
    "2. **Using GPU without deterministic mode** ‚Üí slight differences each run\n",
    "3. **DataLoader multiprocessing** ‚Üí each worker has different RNG state\n",
    "4. **Async operations** ‚Üí execution order varies\n",
    "5. **Library updates** ‚Üí different PyTorch versions may have different numerics\n",
    "\n",
    "### üîß Debugging Checklist\n",
    "\n",
    "When results aren't reproducible:\n",
    "\n",
    "- [ ] Did you call `set_seed()` before training?\n",
    "- [ ] Are you using CPU or GPU? (GPU has non-determinism)\n",
    "- [ ] Did you set `num_workers=0` in DataLoader?\n",
    "- [ ] Are you using the same PyTorch version?\n",
    "- [ ] Did you save the random seed with the experiment?\n",
    "- [ ] Are there any async operations (e.g., `.to(device, non_blocking=True)`)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee39375",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Complete these exercises to test your understanding:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc182f53",
   "metadata": {},
   "source": [
    "### Exercise 1: Break Determinism\n",
    "\n",
    "Modify the training code to intentionally make it non-reproducible. Run it twice and verify the results differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e2774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Remove the set_seed() call or use a different seed each time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e628c4d4",
   "metadata": {},
   "source": [
    "### Exercise 2: Measure Seed Sensitivity\n",
    "\n",
    "Train the same model with 5 different seeds (e.g., 1, 2, 3, 4, 5). Plot the distribution of final test accuracies. How much does the seed matter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ef66a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Use a loop to run training with different seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da24c9b",
   "metadata": {},
   "source": [
    "### Exercise 3: Identify Non-Deterministic Operation\n",
    "\n",
    "The following code snippet has a non-deterministic bug. Find it and fix it.\n",
    "\n",
    "```python\n",
    "set_seed(42)\n",
    "model = SimpleMLP(10, [20], 2)\n",
    "data = torch.randn(100, 10)\n",
    "labels = torch.randint(0, 2, (100,))\n",
    "\n",
    "# Training loop\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "for epoch in range(3):\n",
    "    perm = torch.randperm(100)  # BUG: creates new random permutation\n",
    "    x_batch = data[perm[:32]]\n",
    "    y_batch = labels[perm[:32]]\n",
    "    \n",
    "    output = model(x_batch)\n",
    "    loss = nn.CrossEntropyLoss()(output, y_batch)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43bee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your fixed code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aeacfd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Solutions\n",
    "\n",
    "<details>\n",
    "<summary>Click to reveal solutions</summary>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856ccb04",
   "metadata": {},
   "source": [
    "### Solution 1: Break Determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d21985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Comment out set_seed or use random seed\n",
    "import time\n",
    "\n",
    "def run_non_deterministic():\n",
    "    # Use current time as seed (different each run)\n",
    "    seed = int(time.time() * 1000) % 10000\n",
    "    set_seed(seed)\n",
    "    \n",
    "    model = SimpleMLP(10, [20], 2)\n",
    "    x = torch.randn(4, 10)\n",
    "    return model(x).sum().item()\n",
    "\n",
    "result1 = run_non_deterministic()\n",
    "result2 = run_non_deterministic()\n",
    "print(f\"Run 1: {result1:.6f}\")\n",
    "print(f\"Run 2: {result2:.6f}\")\n",
    "print(f\"Different: {result1 != result2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc639fd8",
   "metadata": {},
   "source": [
    "### Solution 2: Seed Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf6d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Train with multiple seeds\n",
    "seeds = [1, 2, 3, 4, 5]\n",
    "accuracies = []\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"\\nTraining with seed={seed}...\")\n",
    "    _, metrics = run_training_experiment(seed=seed, name=f\"seed_{seed}\")\n",
    "    accuracies.append(metrics['accuracy'])\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(seeds, accuracies, color='steelblue', alpha=0.7)\n",
    "plt.axhline(np.mean(accuracies), color='red', linestyle='--', label=f'Mean: {np.mean(accuracies):.4f}')\n",
    "plt.xlabel('Seed', fontsize=12)\n",
    "plt.ylabel('Test Accuracy', fontsize=12)\n",
    "plt.title('Seed Sensitivity Analysis', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / \"seed_sensitivity.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAccuracies: {accuracies}\")\n",
    "print(f\"Mean: {np.mean(accuracies):.4f}\")\n",
    "print(f\"Std: {np.std(accuracies):.4f}\")\n",
    "print(f\"Range: [{min(accuracies):.4f}, {max(accuracies):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845956fe",
   "metadata": {},
   "source": [
    "### Solution 3: Fix Non-Deterministic Bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc51f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Set seed inside loop or use fixed permutation\n",
    "set_seed(42)\n",
    "model = SimpleMLP(10, [20], 2)\n",
    "data = torch.randn(100, 10)\n",
    "labels = torch.randint(0, 2, (100,))\n",
    "\n",
    "# Fix 1: Set seed at start (affects all subsequent random ops)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "for epoch in range(3):\n",
    "    perm = torch.randperm(100)  # Now deterministic\n",
    "    x_batch = data[perm[:32]]\n",
    "    y_batch = labels[perm[:32]]\n",
    "    \n",
    "    output = model(x_batch)\n",
    "    loss = nn.CrossEntropyLoss()(output, y_batch)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Alternative Fix 2: Use DataLoader with fixed seed\n",
    "# This is cleaner and how you should do it in practice\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "dataset = TensorDataset(data, labels)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True, \n",
    "                   generator=torch.Generator().manual_seed(42))\n",
    "print(\"‚úì Bug fixed: now deterministic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b2f6e",
   "metadata": {},
   "source": [
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0473bed8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Notebook 02**: Sanity checks - learn to overfit a tiny batch (the #1 debugging technique)\n",
    "- **Notebook 03**: Optimization dynamics - LR schedules, optimizers, regularization\n",
    "- **Notebook 04**: Monitoring & error analysis - confusion matrices, worst errors\n",
    "\n",
    "**Key lesson**: Reproducibility isn't optional - it's the foundation of reliable ML engineering."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
