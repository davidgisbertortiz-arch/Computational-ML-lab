{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a2476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Setup ===\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent.parent.parent))\n",
    "\n",
    "from modules._import_helper import safe_import_from\n",
    "\n",
    "set_seed = safe_import_from('00_repo_standards.src.mlphys_core', 'set_seed')\n",
    "PINN, PINNConfig, compute_gradient = safe_import_from(\n",
    "    '07_physics_informed_ml.src.pinn_base',\n",
    "    'PINN', 'PINNConfig', 'compute_gradient'\n",
    ")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "\n",
    "reports_dir = Path.cwd().parent / 'reports'\n",
    "reports_dir.mkdir(exist_ok=True)\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print(\"‚úì Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff83bbdf",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. The Inverse Problem\n",
    "\n",
    "### Damped Harmonic Oscillator\n",
    "\n",
    "$$\\ddot{x} + 2\\gamma\\dot{x} + \\omega^2 x = 0$$\n",
    "\n",
    "**Forward problem**: Given $(\\gamma, \\omega)$, find $x(t)$\n",
    "\n",
    "**Inverse problem**: Given noisy observations $\\{(t_i, x_i)\\}$, find $\\gamma$\n",
    "\n",
    "### Analytical Solution (Underdamped: $\\gamma < \\omega$)\n",
    "\n",
    "$$x(t) = e^{-\\gamma t} \\left[ A \\cos(\\omega_d t) + B \\sin(\\omega_d t) \\right]$$\n",
    "\n",
    "where $\\omega_d = \\sqrt{\\omega^2 - \\gamma^2}$\n",
    "\n",
    "### Why Is This Hard?\n",
    "\n",
    "1. **Non-convex**: Multiple local minima in parameter space\n",
    "2. **Ill-conditioned**: Small data changes ‚Üí large parameter changes\n",
    "3. **Noise sensitivity**: Noise in $x$ propagates to $\\gamma$ estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd469611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Generate synthetic data ===\n",
    "def damped_oscillator_analytical(omega, gamma, x0, v0, t):\n",
    "    \"\"\"Analytical solution for underdamped oscillator.\"\"\"\n",
    "    omega_d = np.sqrt(omega**2 - gamma**2)\n",
    "    A = x0\n",
    "    B = (v0 + gamma * x0) / omega_d\n",
    "    x = np.exp(-gamma * t) * (A * np.cos(omega_d * t) + B * np.sin(omega_d * t))\n",
    "    return x\n",
    "\n",
    "# True parameters (we want to recover gamma)\n",
    "omega_true = 2.0      # Known angular frequency\n",
    "gamma_true = 0.3      # UNKNOWN damping coefficient\n",
    "x0, v0 = 1.0, 0.0     # Initial conditions\n",
    "\n",
    "# Generate observations\n",
    "np.random.seed(SEED)\n",
    "n_obs = 30\n",
    "t_obs = np.sort(np.random.uniform(0, 10, n_obs))\n",
    "x_clean = damped_oscillator_analytical(omega_true, gamma_true, x0, v0, t_obs)\n",
    "\n",
    "# Add noise\n",
    "noise_level = 0.05\n",
    "x_obs = x_clean + noise_level * np.random.randn(n_obs)\n",
    "\n",
    "# Dense evaluation for plotting\n",
    "t_dense = np.linspace(0, 10, 200)\n",
    "x_true = damped_oscillator_analytical(omega_true, gamma_true, x0, v0, t_dense)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(t_dense, x_true, 'k-', lw=2, label='True solution')\n",
    "plt.scatter(t_obs, x_obs, c='r', s=50, zorder=5, label=f'Observations (n={n_obs})')\n",
    "plt.xlabel('Time t')\n",
    "plt.ylabel('Position x')\n",
    "plt.title(f'Inverse Problem Setup\\nTrue Œ≥ = {gamma_true} (unknown), œâ = {omega_true} (known)')\n",
    "plt.legend()\n",
    "plt.savefig(reports_dir / '05_inverse_problem_setup.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Observations: {n_obs} points\")\n",
    "print(f\"Noise level: {noise_level} (œÉ ‚âà {noise_level * np.std(x_clean):.4f})\")\n",
    "print(f\"\\nGoal: Recover Œ≥_true = {gamma_true}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7cb1df",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Inverse PINN Formulation\n",
    "\n",
    "### Architecture\n",
    "\n",
    "**Trainable variables**:\n",
    "1. NN weights $\\theta$ (predict $\\hat{x}(t)$)\n",
    "2. Unknown parameter $\\gamma$ (scalar)\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "$$\\mathcal{L} = \\mathcal{L}_{\\text{data}} + \\lambda_1 \\mathcal{L}_{\\text{physics}} + \\lambda_2 \\mathcal{L}_{\\text{IC}}$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\\mathcal{L}_{\\text{data}} = \\frac{1}{N_{\\text{obs}}} \\sum_i (\\hat{x}(t_i) - x_i^{\\text{obs}})^2$$\n",
    "\n",
    "$$\\mathcal{L}_{\\text{physics}} = \\frac{1}{N_c} \\sum_j \\left| \\ddot{\\hat{x}}(t_j) + 2\\gamma \\dot{\\hat{x}}(t_j) + \\omega^2 \\hat{x}(t_j) \\right|^2$$\n",
    "\n",
    "**Key**: $\\gamma$ appears in $\\mathcal{L}_{\\text{physics}}$ and is optimized jointly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a79f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Inverse PINN Implementation ===\n",
    "\n",
    "class InversePINN:\n",
    "    \"\"\"\n",
    "    PINN for inverse problem: identify damping coefficient Œ≥.\n",
    "    \n",
    "    ODE: x'' + 2*gamma*x' + omega^2*x = 0\n",
    "    Known: omega, initial conditions, sparse observations\n",
    "    Unknown: gamma (learned as trainable parameter)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        omega: float,\n",
    "        x0: float,\n",
    "        v0: float,\n",
    "        t_max: float,\n",
    "        gamma_init: float = 0.1,  # Initial guess for gamma\n",
    "        n_collocation: int = 200,\n",
    "        hidden_dims: list = [64, 64, 64],\n",
    "        epochs: int = 5000,\n",
    "        lr: float = 1e-3,\n",
    "        lr_gamma: float = 1e-2,  # Separate LR for gamma\n",
    "        lambda_physics: float = 1.0,\n",
    "        lambda_ic: float = 10.0,\n",
    "    ):\n",
    "        self.omega = omega\n",
    "        self.x0 = x0\n",
    "        self.v0 = v0\n",
    "        self.t_max = t_max\n",
    "        self.epochs = epochs\n",
    "        self.lambda_physics = lambda_physics\n",
    "        self.lambda_ic = lambda_ic\n",
    "        \n",
    "        # Neural network for x(t)\n",
    "        pinn_config = PINNConfig(\n",
    "            input_dim=1, output_dim=1,\n",
    "            hidden_dims=hidden_dims,\n",
    "            activation='tanh'\n",
    "        )\n",
    "        self.model = PINN(pinn_config)\n",
    "        \n",
    "        # TRAINABLE parameter gamma\n",
    "        self.gamma = nn.Parameter(torch.tensor([gamma_init], dtype=torch.float32))\n",
    "        \n",
    "        # Optimizers\n",
    "        self.optimizer_nn = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.optimizer_gamma = torch.optim.Adam([self.gamma], lr=lr_gamma)\n",
    "        \n",
    "        # Collocation points\n",
    "        self.t_col = torch.linspace(0, t_max, n_collocation).view(-1, 1)\n",
    "        self.t_col.requires_grad = True\n",
    "        \n",
    "        # IC point\n",
    "        self.t_ic = torch.tensor([[0.0]], requires_grad=True)\n",
    "    \n",
    "    def physics_residual(self, t):\n",
    "        \"\"\"Compute ODE residual with current gamma estimate.\"\"\"\n",
    "        x = self.model(t)\n",
    "        x_t = compute_gradient(x, t, order=1)\n",
    "        x_tt = compute_gradient(x, t, order=2)\n",
    "        \n",
    "        # r = x'' + 2*gamma*x' + omega^2*x\n",
    "        residual = x_tt + 2 * self.gamma * x_t + self.omega**2 * x\n",
    "        return residual\n",
    "    \n",
    "    def train(self, t_obs, x_obs, verbose=500):\n",
    "        \"\"\"Train with observations.\"\"\"\n",
    "        t_obs_tensor = torch.tensor(t_obs, dtype=torch.float32).view(-1, 1)\n",
    "        x_obs_tensor = torch.tensor(x_obs, dtype=torch.float32).view(-1, 1)\n",
    "        \n",
    "        history = {\n",
    "            'loss': [], 'loss_data': [], 'loss_physics': [], 'loss_ic': [],\n",
    "            'gamma': []\n",
    "        }\n",
    "        \n",
    "        self.model.train()\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            self.optimizer_nn.zero_grad()\n",
    "            self.optimizer_gamma.zero_grad()\n",
    "            \n",
    "            # Data loss\n",
    "            x_pred_obs = self.model(t_obs_tensor)\n",
    "            loss_data = torch.mean((x_pred_obs - x_obs_tensor)**2)\n",
    "            \n",
    "            # Physics loss\n",
    "            residual = self.physics_residual(self.t_col)\n",
    "            loss_physics = torch.mean(residual**2)\n",
    "            \n",
    "            # IC loss\n",
    "            x_ic = self.model(self.t_ic)\n",
    "            v_ic = compute_gradient(x_ic, self.t_ic, order=1)\n",
    "            loss_ic = (x_ic - self.x0)**2 + (v_ic - self.v0)**2\n",
    "            loss_ic = loss_ic.squeeze()\n",
    "            \n",
    "            # Total loss\n",
    "            loss = loss_data + self.lambda_physics * loss_physics + self.lambda_ic * loss_ic\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer_nn.step()\n",
    "            self.optimizer_gamma.step()\n",
    "            \n",
    "            # Enforce gamma > 0 (physical constraint)\n",
    "            with torch.no_grad():\n",
    "                self.gamma.clamp_(min=0.001)\n",
    "            \n",
    "            # Record\n",
    "            history['loss'].append(loss.item())\n",
    "            history['loss_data'].append(loss_data.item())\n",
    "            history['loss_physics'].append(loss_physics.item())\n",
    "            history['loss_ic'].append(loss_ic.item())\n",
    "            history['gamma'].append(self.gamma.item())\n",
    "            \n",
    "            if verbose > 0 and (epoch + 1) % verbose == 0:\n",
    "                print(f\"Epoch {epoch+1:5d} | Loss: {loss.item():.6f} | \"\n",
    "                      f\"Œ≥_est: {self.gamma.item():.4f}\")\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def predict(self, t):\n",
    "        \"\"\"Predict x(t).\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            t_tensor = torch.tensor(t, dtype=torch.float32).view(-1, 1)\n",
    "            return self.model(t_tensor).numpy().flatten()\n",
    "    \n",
    "    def get_gamma(self):\n",
    "        \"\"\"Return estimated gamma.\"\"\"\n",
    "        return self.gamma.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5593250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Train inverse PINN ===\n",
    "set_seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "inv_pinn = InversePINN(\n",
    "    omega=omega_true,\n",
    "    x0=x0, v0=v0,\n",
    "    t_max=10.0,\n",
    "    gamma_init=0.1,  # Initial guess (intentionally wrong)\n",
    "    n_collocation=300,\n",
    "    hidden_dims=[64, 64, 64],\n",
    "    epochs=8000,\n",
    "    lr=1e-3,\n",
    "    lr_gamma=5e-3,\n",
    "    lambda_physics=1.0,\n",
    "    lambda_ic=10.0,\n",
    ")\n",
    "\n",
    "print(f\"Initial Œ≥ guess: {inv_pinn.get_gamma():.4f}\")\n",
    "print(f\"True Œ≥: {gamma_true}\")\n",
    "print(\"\\nTraining...\")\n",
    "\n",
    "history = inv_pinn.train(t_obs, x_obs, verbose=1000)\n",
    "\n",
    "gamma_est = inv_pinn.get_gamma()\n",
    "gamma_error = abs(gamma_est - gamma_true)\n",
    "rel_error = gamma_error / gamma_true * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PARAMETER IDENTIFICATION RESULT\")\n",
    "print(\"=\"*50)\n",
    "print(f\"True Œ≥:      {gamma_true:.4f}\")\n",
    "print(f\"Estimated Œ≥: {gamma_est:.4f}\")\n",
    "print(f\"Error:       {gamma_error:.4f} ({rel_error:.2f}%)\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c68880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Visualization ===\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Training convergence\n",
    "ax = axes[0, 0]\n",
    "ax.semilogy(history['loss'], 'k-', lw=2, label='Total')\n",
    "ax.semilogy(history['loss_data'], 'b--', alpha=0.7, label='Data')\n",
    "ax.semilogy(history['loss_physics'], 'r:', alpha=0.7, label='Physics')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training Convergence')\n",
    "ax.legend()\n",
    "\n",
    "# Gamma evolution\n",
    "ax = axes[0, 1]\n",
    "ax.plot(history['gamma'], 'b-', lw=2)\n",
    "ax.axhline(gamma_true, color='r', linestyle='--', lw=2, label=f'True Œ≥ = {gamma_true}')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Œ≥ estimate')\n",
    "ax.set_title('Parameter Learning Trajectory')\n",
    "ax.legend()\n",
    "\n",
    "# Solution comparison\n",
    "ax = axes[1, 0]\n",
    "x_pred = inv_pinn.predict(t_dense)\n",
    "ax.plot(t_dense, x_true, 'k-', lw=2, label='True (Œ≥_true)')\n",
    "ax.plot(t_dense, x_pred, 'b--', lw=2, label=f'PINN (Œ≥_est={gamma_est:.4f})')\n",
    "ax.scatter(t_obs, x_obs, c='r', s=50, zorder=5, label='Observations')\n",
    "ax.set_xlabel('Time t')\n",
    "ax.set_ylabel('x(t)')\n",
    "ax.set_title('Solution Comparison')\n",
    "ax.legend()\n",
    "\n",
    "# Solution with wrong gamma\n",
    "ax = axes[1, 1]\n",
    "x_wrong = damped_oscillator_analytical(omega_true, 0.1, x0, v0, t_dense)  # Wrong gamma\n",
    "ax.plot(t_dense, x_true, 'k-', lw=2, label=f'True (Œ≥={gamma_true})')\n",
    "ax.plot(t_dense, x_pred, 'b--', lw=2, label=f'PINN (Œ≥={gamma_est:.3f})')\n",
    "ax.plot(t_dense, x_wrong, 'g:', lw=2, alpha=0.7, label='Initial guess (Œ≥=0.1)')\n",
    "ax.set_xlabel('Time t')\n",
    "ax.set_ylabel('x(t)')\n",
    "ax.set_title('Effect of Correct vs Wrong Œ≥')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / '05_inverse_pinn_result.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc38d0be",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Experiment: Sensitivity to Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea59afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Noise sensitivity ===\n",
    "noise_levels = [0.01, 0.05, 0.1, 0.2]\n",
    "results_noise = []\n",
    "\n",
    "print(\"EXPERIMENT: Sensitivity to Noise\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for noise in noise_levels:\n",
    "    set_seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    \n",
    "    # Generate noisy data\n",
    "    x_noisy = x_clean + noise * np.random.randn(n_obs)\n",
    "    \n",
    "    # Train\n",
    "    inv_pinn_test = InversePINN(\n",
    "        omega=omega_true, x0=x0, v0=v0, t_max=10.0,\n",
    "        gamma_init=0.1, epochs=5000, lr_gamma=5e-3\n",
    "    )\n",
    "    _ = inv_pinn_test.train(t_obs, x_noisy, verbose=0)\n",
    "    \n",
    "    gamma_est = inv_pinn_test.get_gamma()\n",
    "    error = abs(gamma_est - gamma_true)\n",
    "    rel_error = error / gamma_true * 100\n",
    "    \n",
    "    results_noise.append({\n",
    "        'noise': noise,\n",
    "        'gamma_est': gamma_est,\n",
    "        'error': error,\n",
    "        'rel_error': rel_error,\n",
    "    })\n",
    "    \n",
    "    print(f\"Noise={noise:.2f} | Œ≥_est={gamma_est:.4f} | Error={error:.4f} ({rel_error:.1f}%)\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "noises = [r['noise'] for r in results_noise]\n",
    "errors = [r['error'] for r in results_noise]\n",
    "ax.plot(noises, errors, 'ko-', lw=2, ms=10)\n",
    "ax.set_xlabel('Noise Level')\n",
    "ax.set_ylabel('|Œ≥_est - Œ≥_true|')\n",
    "ax.set_title('Parameter Estimation Error vs Noise')\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / '05_noise_sensitivity.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333b92d1",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Experiment: Sensitivity to Data Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3646ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data sparsity ===\n",
    "n_obs_values = [10, 20, 30, 50, 100]\n",
    "results_sparsity = []\n",
    "\n",
    "print(\"EXPERIMENT: Sensitivity to Data Sparsity\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for n in n_obs_values:\n",
    "    set_seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    \n",
    "    # Generate data\n",
    "    t_sparse = np.sort(np.random.uniform(0, 10, n))\n",
    "    x_clean_sparse = damped_oscillator_analytical(omega_true, gamma_true, x0, v0, t_sparse)\n",
    "    x_sparse = x_clean_sparse + 0.05 * np.random.randn(n)\n",
    "    \n",
    "    # Train\n",
    "    inv_pinn_test = InversePINN(\n",
    "        omega=omega_true, x0=x0, v0=v0, t_max=10.0,\n",
    "        gamma_init=0.1, epochs=5000, lr_gamma=5e-3\n",
    "    )\n",
    "    _ = inv_pinn_test.train(t_sparse, x_sparse, verbose=0)\n",
    "    \n",
    "    gamma_est = inv_pinn_test.get_gamma()\n",
    "    error = abs(gamma_est - gamma_true)\n",
    "    \n",
    "    results_sparsity.append({\n",
    "        'n_obs': n,\n",
    "        'gamma_est': gamma_est,\n",
    "        'error': error,\n",
    "    })\n",
    "    \n",
    "    print(f\"N_obs={n:3d} | Œ≥_est={gamma_est:.4f} | Error={error:.4f}\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ns = [r['n_obs'] for r in results_sparsity]\n",
    "errors = [r['error'] for r in results_sparsity]\n",
    "ax.plot(ns, errors, 'ko-', lw=2, ms=10)\n",
    "ax.set_xlabel('Number of Observations')\n",
    "ax.set_ylabel('|Œ≥_est - Œ≥_true|')\n",
    "ax.set_title('Parameter Estimation Error vs Data Amount')\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / '05_sparsity_sensitivity.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293b32e5",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Experiment: Sensitivity to Initial Guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba86f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Initial guess sensitivity ===\n",
    "gamma_inits = [0.05, 0.1, 0.2, 0.5, 0.8]\n",
    "results_init = []\n",
    "\n",
    "print(\"EXPERIMENT: Sensitivity to Initial Guess\")\n",
    "print(f\"True Œ≥ = {gamma_true}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for g_init in gamma_inits:\n",
    "    set_seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    \n",
    "    inv_pinn_test = InversePINN(\n",
    "        omega=omega_true, x0=x0, v0=v0, t_max=10.0,\n",
    "        gamma_init=g_init,\n",
    "        epochs=5000, lr_gamma=5e-3\n",
    "    )\n",
    "    history_test = inv_pinn_test.train(t_obs, x_obs, verbose=0)\n",
    "    \n",
    "    gamma_est = inv_pinn_test.get_gamma()\n",
    "    error = abs(gamma_est - gamma_true)\n",
    "    \n",
    "    results_init.append({\n",
    "        'gamma_init': g_init,\n",
    "        'gamma_est': gamma_est,\n",
    "        'error': error,\n",
    "        'history': history_test['gamma'],\n",
    "    })\n",
    "    \n",
    "    print(f\"Œ≥_init={g_init:.2f} | Œ≥_est={gamma_est:.4f} | Error={error:.4f}\")\n",
    "\n",
    "# Plot learning trajectories\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(results_init)))\n",
    "for i, r in enumerate(results_init):\n",
    "    ax.plot(r['history'], color=colors[i], lw=2, label=f\"Œ≥_init={r['gamma_init']:.2f}\")\n",
    "ax.axhline(gamma_true, color='r', linestyle='--', lw=2, label=f'True Œ≥={gamma_true}')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Œ≥ estimate')\n",
    "ax.set_title('Parameter Learning from Different Initial Guesses')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / '05_initial_guess_sensitivity.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2210207b",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Summary Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc435a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Save summary ===\n",
    "summary = f\"\"\"\n",
    "# Inverse Problem: Parameter Identification - Results Summary\n",
    "\n",
    "**Date**: {time.strftime('%Y-%m-%d %H:%M')}\n",
    "**Seed**: {SEED}\n",
    "\n",
    "## Problem Setup\n",
    "\n",
    "- ODE: x'' + 2Œ≥x' + œâ¬≤x = 0 (damped oscillator)\n",
    "- Known: œâ = {omega_true}\n",
    "- Unknown: Œ≥ (true value = {gamma_true})\n",
    "- Observations: {n_obs} noisy measurements\n",
    "\n",
    "## Main Result\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| True Œ≥ | {gamma_true:.4f} |\n",
    "| Estimated Œ≥ | {gamma_est:.4f} |\n",
    "| Absolute Error | {gamma_error:.4f} |\n",
    "| Relative Error | {rel_error:.2f}% |\n",
    "\n",
    "## Noise Sensitivity\n",
    "\n",
    "| Noise Level | Œ≥_est | Error |\n",
    "|-------------|-------|-------|\n",
    "\"\"\" + \"\\n\".join([f\"| {r['noise']:.2f} | {r['gamma_est']:.4f} | {r['error']:.4f} |\" for r in results_noise]) + \"\"\"\n",
    "\n",
    "## Data Sparsity Sensitivity\n",
    "\n",
    "| N_obs | Œ≥_est | Error |\n",
    "|-------|-------|-------|\n",
    "\"\"\" + \"\\n\".join([f\"| {r['n_obs']} | {r['gamma_est']:.4f} | {r['error']:.4f} |\" for r in results_sparsity]) + \"\"\"\n",
    "\n",
    "## Initial Guess Sensitivity\n",
    "\n",
    "| Œ≥_init | Œ≥_est | Error |\n",
    "|--------|-------|-------|\n",
    "\"\"\" + \"\\n\".join([f\"| {r['gamma_init']:.2f} | {r['gamma_est']:.4f} | {r['error']:.4f} |\" for r in results_init]) + \"\"\"\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "1. **PINN successfully identifies damping coefficient** from sparse noisy data\n",
    "2. **Noise increases error** but physics constraint provides regularization\n",
    "3. **More data helps** but even 10 points give reasonable estimates\n",
    "4. **Initial guess matters less** than for pure optimization (NN finds solution path)\n",
    "5. **Physics constraint is key**: Without it, inverse problem is ill-posed\n",
    "\n",
    "## When Parameter ID Works\n",
    "\n",
    "‚úÖ **Good conditions**:\n",
    "- Parameter affects solution significantly (sensitivity)\n",
    "- Physics model is correct\n",
    "- Data spans enough dynamics\n",
    "\n",
    "‚ùå **Challenging conditions**:\n",
    "- Parameters are weakly identifiable\n",
    "- Very high noise\n",
    "- Model mismatch (wrong physics)\n",
    "\n",
    "## Comparison to Classical Methods\n",
    "\n",
    "| Method | Advantages | Disadvantages |\n",
    "|--------|------------|---------------|\n",
    "| Least squares | Fast, well-understood | Needs analytical gradients |\n",
    "| PINN | Flexible, mesh-free | Slower, hyperparameter tuning |\n",
    "| Bayesian | Uncertainty quantification | Computationally expensive |\n",
    "\"\"\"\n",
    "\n",
    "with open(reports_dir / '05_inverse_problem_summary.md', 'w') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(summary)\n",
    "print(f\"\\n‚úì Summary saved to {reports_dir / '05_inverse_problem_summary.md'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35726170",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Mini Exercises\n",
    "\n",
    "**Exercise 1**: Try identifying œâ instead of Œ≥ (assume Œ≥ is known). Is it easier or harder?\n",
    "\n",
    "**Exercise 2**: Identify BOTH Œ≥ and œâ simultaneously. Does it work?\n",
    "\n",
    "**Exercise 3**: Add a simple uncertainty estimate using bootstrap (train multiple times with different subsets).\n",
    "\n",
    "**Exercise 4**: What happens if the physics model is wrong (e.g., assume no damping when there is)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f589994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Exercise 1: Identify omega instead ===\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aaf3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Exercise 2: Identify both parameters ===\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316bc049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Exercise 3: Bootstrap uncertainty ===\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318a529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Exercise 4: Model mismatch ===\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0c32fe",
   "metadata": {},
   "source": [
    "---\n",
    "## Key Takeaways\n",
    "\n",
    "### ‚úÖ What We Learned\n",
    "\n",
    "1. **PINNs excel at inverse problems**: Physics constraint regularizes parameter estimation\n",
    "2. **Joint optimization works**: NN weights and physics parameters optimize together\n",
    "3. **Robust to noise**: Physics provides prior knowledge that helps with noisy data\n",
    "4. **Data efficiency**: Works with sparse observations if physics is correct\n",
    "\n",
    "### ‚ö†Ô∏è Limitations\n",
    "\n",
    "1. **Identifiability**: Some parameters may not be uniquely determinable\n",
    "2. **Model mismatch**: Wrong physics ‚Üí wrong parameters\n",
    "3. **Multiple parameters**: Harder, may have multiple minima\n",
    "4. **No uncertainty**: Basic PINN doesn't quantify confidence\n",
    "\n",
    "### üí° When to Use PINNs for Inverse Problems?\n",
    "\n",
    "- **Parameter discovery** from experimental data\n",
    "- **System identification** for dynamical systems\n",
    "- **When classical methods need analytical derivatives** (PINN uses autodiff)\n",
    "- **Multi-physics problems** where parameters appear in complex ways"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
