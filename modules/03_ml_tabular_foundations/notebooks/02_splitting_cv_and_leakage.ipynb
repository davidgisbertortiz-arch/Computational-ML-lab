{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33496011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "repo_root = Path().resolve().parents[2]\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "from modules._import_helper import safe_import_from\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "set_seed = safe_import_from('00_repo_standards.src.mlphys_core.seeding', 'set_seed')\n",
    "load_data, get_feature_columns, split_data = safe_import_from(\n",
    "    '03_ml_tabular_foundations.src.data',\n",
    "    'load_data', 'get_feature_columns', 'split_data'\n",
    ")\n",
    "\n",
    "set_seed(42)\n",
    "reports_dir = Path(\"../reports\")\n",
    "reports_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26396ab1",
   "metadata": {},
   "source": [
    "## 1. The Importance of Proper Splitting\n",
    "\n",
    "**Why splits matter**:\n",
    "- **Train set**: Learn patterns (fit model parameters)\n",
    "- **Validation set**: Tune hyperparameters, select models\n",
    "- **Test set**: Final unbiased evaluation (touch ONCE!)\n",
    "\n",
    "**Common mistakes**:\n",
    "1. ‚ùå Training on test data\n",
    "2. ‚ùå Using full data to compute statistics (mean, std) before splitting\n",
    "3. ‚ùå Tuning on test set\n",
    "4. ‚ùå Not stratifying with class imbalance\n",
    "5. ‚ùå Data leakage through preprocessing\n",
    "\n",
    "**Golden rule**: Test set is sacred. Pretend it doesn't exist until final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345bf789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = load_data()\n",
    "feature_cols = get_feature_columns(df)\n",
    "X = df[feature_cols].values\n",
    "y = df['is_signal'].values\n",
    "\n",
    "print(f\"Dataset: {X.shape[0]:,} samples, {X.shape[1]} features\")\n",
    "print(f\"Class balance: {y.mean():.1%} signal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6877bfe",
   "metadata": {},
   "source": [
    "## 2. Split Strategy: Train/Val/Test\n",
    "\n",
    "**Recommended split**: 60% train / 20% val / 20% test\n",
    "\n",
    "**Why this ratio?**:\n",
    "- Train: Need enough data to learn patterns\n",
    "- Val: Need enough to estimate generalization reliably (not too small)\n",
    "- Test: Final evaluation, keep same size as val for fair comparison\n",
    "\n",
    "**Stratification**: Maintain class balance across all splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487728d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split using module's function (proper stratified split)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y, test_size=0.2, val_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Split Verification:\")\n",
    "print(f\"Train: {X_train.shape[0]:,} samples ({X_train.shape[0]/X.shape[0]:.1%}), signal rate: {y_train.mean():.1%}\")\n",
    "print(f\"Val:   {X_val.shape[0]:,} samples ({X_val.shape[0]/X.shape[0]:.1%}), signal rate: {y_val.mean():.1%}\")\n",
    "print(f\"Test:  {X_test.shape[0]:,} samples ({X_test.shape[0]/X.shape[0]:.1%}), signal rate: {y_test.mean():.1%}\")\n",
    "\n",
    "# Verify no overlap\n",
    "train_val_overlap = len(set(range(len(X_train))) & set(range(len(X_train), len(X_train) + len(X_val))))\n",
    "print(f\"\\n‚úÖ No data overlap: train ‚à© val = {train_val_overlap}\")\n",
    "print(f\"‚úÖ Stratification preserved: all splits have ~{y.mean():.1%} signal rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8c8f2c",
   "metadata": {},
   "source": [
    "## 3. Cross-Validation for Robust Evaluation\n",
    "\n",
    "**Problem**: Single train/val split may be lucky or unlucky.\n",
    "\n",
    "**Solution**: k-fold CV averages over multiple splits.\n",
    "\n",
    "**Stratified k-Fold CV**:\n",
    "1. Split data into k folds\n",
    "2. For each fold i:\n",
    "   - Train on k-1 folds\n",
    "   - Validate on fold i\n",
    "3. Average validation metrics across all folds\n",
    "\n",
    "**When to use CV**:\n",
    "- ‚úÖ Model selection (compare architectures)\n",
    "- ‚úÖ Hyperparameter tuning\n",
    "- ‚ùå Final test evaluation (use held-out test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7f4fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate stratified k-fold CV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Use train+val data for CV (hold out test set for final eval)\n",
    "X_train_val = np.vstack([X_train, X_val])\n",
    "y_train_val = np.concatenate([y_train, y_val])\n",
    "\n",
    "# Simple logistic regression (we'll fix preprocessing leakage later)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# For now, we'll standardize INSIDE cv (proper way) vs OUTSIDE cv (leakage)\n",
    "# We'll demonstrate both approaches\n",
    "\n",
    "print(\"5-Fold Stratified Cross-Validation:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "fold_scores = []\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X_train_val, y_train_val)):\n",
    "    X_fold_train, X_fold_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "    y_fold_train, y_fold_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "    \n",
    "    # ‚úÖ CORRECT: Fit scaler on train fold only\n",
    "    scaler = StandardScaler()\n",
    "    X_fold_train_scaled = scaler.fit_transform(X_fold_train)\n",
    "    X_fold_val_scaled = scaler.transform(X_fold_val)\n",
    "    \n",
    "    # Train model\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(X_fold_train_scaled, y_fold_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict_proba(X_fold_val_scaled)[:, 1]\n",
    "    auc = roc_auc_score(y_fold_val, y_pred)\n",
    "    fold_scores.append(auc)\n",
    "    \n",
    "    print(f\"Fold {fold+1}: AUC = {auc:.4f} (train: {len(y_fold_train):,}, val: {len(y_fold_val):,})\")\n",
    "\n",
    "mean_auc = np.mean(fold_scores)\n",
    "std_auc = np.std(fold_scores)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Mean AUC: {mean_auc:.4f} ¬± {std_auc:.4f}\")\n",
    "print(f\"95% CI: [{mean_auc - 1.96*std_auc:.4f}, {mean_auc + 1.96*std_auc:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e3345a",
   "metadata": {},
   "source": [
    "## 4. Data Leakage: The Silent Killer\n",
    "\n",
    "**Definition**: Using information from validation/test sets during training.\n",
    "\n",
    "**Why it's dangerous**:\n",
    "- Model sees \"future\" information\n",
    "- Overestimates performance\n",
    "- Fails in production\n",
    "\n",
    "**Common leakage sources**:\n",
    "1. **Preprocessing on full data before split** ‚Üê Most common!\n",
    "2. Target encoding using global statistics\n",
    "3. Feature selection using full data\n",
    "4. Normalization using test set statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0046149c",
   "metadata": {},
   "source": [
    "## 5. Demonstration: Leaky Pipeline (‚ùå WRONG)\n",
    "\n",
    "Let's deliberately create a leaky pipeline to see the effect.\n",
    "\n",
    "**Mistake**: Standardize using statistics from ALL data (train + val + test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fce319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå WRONG: Fit scaler on ALL data (leakage!)\n",
    "print(\"üö® LEAKY PIPELINE DEMONSTRATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Fit scaler on ENTIRE dataset (WRONG!)\n",
    "scaler_leaky = StandardScaler()\n",
    "X_all_scaled = scaler_leaky.fit_transform(X)  # Using test data to compute mean/std!\n",
    "\n",
    "# Step 2: Split AFTER scaling\n",
    "X_train_leaky, X_temp, y_train_leaky, y_temp = train_test_split(\n",
    "    X_all_scaled, y, test_size=0.4, stratify=y, random_state=42\n",
    ")\n",
    "X_val_leaky, X_test_leaky, y_val_leaky, y_test_leaky = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "# Step 3: Train model\n",
    "model_leaky = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_leaky.fit(X_train_leaky, y_train_leaky)\n",
    "\n",
    "# Step 4: Evaluate\n",
    "y_pred_train_leaky = model_leaky.predict_proba(X_train_leaky)[:, 1]\n",
    "y_pred_val_leaky = model_leaky.predict_proba(X_val_leaky)[:, 1]\n",
    "y_pred_test_leaky = model_leaky.predict_proba(X_test_leaky)[:, 1]\n",
    "\n",
    "auc_train_leaky = roc_auc_score(y_train_leaky, y_pred_train_leaky)\n",
    "auc_val_leaky = roc_auc_score(y_val_leaky, y_pred_val_leaky)\n",
    "auc_test_leaky = roc_auc_score(y_test_leaky, y_pred_test_leaky)\n",
    "\n",
    "print(\"‚ùå LEAKY RESULTS:\")\n",
    "print(f\"  Train AUC: {auc_train_leaky:.4f}\")\n",
    "print(f\"  Val AUC:   {auc_val_leaky:.4f}\")\n",
    "print(f\"  Test AUC:  {auc_test_leaky:.4f}\")\n",
    "print(\"\\n‚ö†Ô∏è Problem: Val/test were used to compute scaling statistics!\")\n",
    "print(\"   ‚Üí Model has seen test data indirectly through mean/std\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169b6f21",
   "metadata": {},
   "source": [
    "## 6. Fixed Pipeline: sklearn Pipelines (‚úÖ CORRECT)\n",
    "\n",
    "**Solution**: Use `sklearn.pipeline.Pipeline` to encapsulate preprocessing.\n",
    "\n",
    "**Why Pipelines prevent leakage**:\n",
    "- `.fit()` on train data only\n",
    "- `.transform()` applied consistently to val/test\n",
    "- No manual bookkeeping of scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b2de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ CORRECT: Use Pipeline\n",
    "print(\"‚úÖ CORRECT PIPELINE (NO LEAKAGE)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create pipeline\n",
    "pipeline_correct = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit on train data ONLY\n",
    "pipeline_correct.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_train_correct = pipeline_correct.predict_proba(X_train)[:, 1]\n",
    "y_pred_val_correct = pipeline_correct.predict_proba(X_val)[:, 1]\n",
    "y_pred_test_correct = pipeline_correct.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc_train_correct = roc_auc_score(y_train, y_pred_train_correct)\n",
    "auc_val_correct = roc_auc_score(y_val, y_pred_val_correct)\n",
    "auc_test_correct = roc_auc_score(y_test, y_pred_test_correct)\n",
    "\n",
    "print(\"‚úÖ CORRECT RESULTS:\")\n",
    "print(f\"  Train AUC: {auc_train_correct:.4f}\")\n",
    "print(f\"  Val AUC:   {auc_val_correct:.4f}\")\n",
    "print(f\"  Test AUC:  {auc_test_correct:.4f}\")\n",
    "print(\"\\n‚úÖ Scaler fit on train data only\")\n",
    "print(\"‚úÖ Val/test transformed using train statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1c5522",
   "metadata": {},
   "source": [
    "## 7. Comparison: Leaky vs. Correct\n",
    "\n",
    "**Key observation**: Leaky pipeline shows **optimistically biased** performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68874751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "comparison = pd.DataFrame({\n",
    "    'Pipeline': ['Leaky ‚ùå', 'Correct ‚úÖ'],\n",
    "    'Train AUC': [auc_train_leaky, auc_train_correct],\n",
    "    'Val AUC': [auc_val_leaky, auc_val_correct],\n",
    "    'Test AUC': [auc_test_leaky, auc_test_correct],\n",
    "    'Val Overestimate': [auc_val_leaky - auc_val_correct, 0],\n",
    "    'Test Overestimate': [auc_test_leaky - auc_test_correct, 0]\n",
    "})\n",
    "\n",
    "print(\"\\nüìä Leaky vs. Correct Pipeline Comparison:\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(2)\n",
    "width = 0.25\n",
    "\n",
    "ax.bar(x - width, [auc_train_leaky, auc_train_correct], width, \n",
    "       label='Train', alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "ax.bar(x, [auc_val_leaky, auc_val_correct], width, \n",
    "       label='Val', alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "ax.bar(x + width, [auc_test_leaky, auc_test_correct], width, \n",
    "       label='Test', alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "ax.set_ylabel('AUC-ROC', fontsize=12)\n",
    "ax.set_title('Leaky vs. Correct Pipeline: Performance Comparison', \n",
    "             fontsize=13, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Leaky ‚ùå', 'Correct ‚úÖ'])\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "ax.set_ylim([0.90, 0.96])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / '02_leaky_vs_correct.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è Leaky pipeline overestimates:\")\n",
    "print(f\"  Val AUC by {(auc_val_leaky - auc_val_correct)*100:.2f} percentage points\")\n",
    "print(f\"  Test AUC by {(auc_test_leaky - auc_test_correct)*100:.2f} percentage points\")\n",
    "print(\"\\nüí° Lesson: Always use Pipelines to prevent accidental leakage!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce0942",
   "metadata": {},
   "source": [
    "## 8. Leakage Detection: Sanity Checks\n",
    "\n",
    "How to catch leakage in your own pipelines:\n",
    "\n",
    "**Red flags**:\n",
    "1. Val/test AUC ‚âà Train AUC (suspiciously good generalization)\n",
    "2. Performance drops dramatically in production\n",
    "3. Preprocessor fit on anything other than train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check implementation\n",
    "def check_for_leakage(model, X_train, X_val, y_train, y_val):\n",
    "    \"\"\"Detect potential leakage via sanity checks.\"\"\"\n",
    "    \n",
    "    checks = []\n",
    "    \n",
    "    # Check 1: Pipeline structure\n",
    "    if hasattr(model, 'named_steps'):\n",
    "        scaler_in_pipeline = 'scaler' in model.named_steps\n",
    "        checks.append(('Pipeline contains scaler', scaler_in_pipeline, '‚úÖ' if scaler_in_pipeline else '‚ùå'))\n",
    "    else:\n",
    "        checks.append(('Pipeline structure', False, '‚ùå Not using Pipeline'))\n",
    "    \n",
    "    # Check 2: Performance gap\n",
    "    y_pred_train = model.predict_proba(X_train)[:, 1]\n",
    "    y_pred_val = model.predict_proba(X_val)[:, 1]\n",
    "    auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "    auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "    gap = auc_train - auc_val\n",
    "    \n",
    "    reasonable_gap = 0.01 < gap < 0.10  # Typical gap for good model\n",
    "    checks.append(('Train-val gap reasonable', reasonable_gap, \n",
    "                   f\"‚úÖ Gap={gap:.4f}\" if reasonable_gap else f\"‚ö†Ô∏è Gap={gap:.4f}\"))\n",
    "    \n",
    "    # Check 3: Val performance not suspiciously high\n",
    "    suspiciously_high = auc_val > 0.99\n",
    "    checks.append(('Val AUC realistic', not suspiciously_high,\n",
    "                   '‚úÖ AUC < 0.99' if not suspiciously_high else f'‚ö†Ô∏è AUC={auc_val:.4f} (too good?)'))\n",
    "    \n",
    "    print(\"üîç Leakage Detection Checks:\")\n",
    "    print(\"=\" * 60)\n",
    "    for check_name, passed, message in checks:\n",
    "        print(f\"  {message} {check_name}\")\n",
    "    \n",
    "    all_passed = all(c[1] for c in checks)\n",
    "    return all_passed\n",
    "\n",
    "# Run checks\n",
    "print(\"Checking CORRECT pipeline:\")\n",
    "check_for_leakage(pipeline_correct, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829fdf84",
   "metadata": {},
   "source": [
    "## 9. Leakage Checklist\n",
    "\n",
    "Save this checklist to `reports/` for reference in all future projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393ede12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate leakage prevention checklist\n",
    "leakage_checklist = \"\"\"\n",
    "# Data Leakage Prevention Checklist\n",
    "\n",
    "## Before Training\n",
    "- [ ] Split data BEFORE any preprocessing\n",
    "- [ ] Use stratified splits for imbalanced data\n",
    "- [ ] Set random_state for reproducibility\n",
    "- [ ] Verify no data overlap between train/val/test\n",
    "\n",
    "## During Preprocessing\n",
    "- [ ] Use sklearn Pipelines for all preprocessing\n",
    "- [ ] Fit preprocessors (scaler, imputer, encoder) on train data ONLY\n",
    "- [ ] Transform val/test using train-fitted preprocessors\n",
    "- [ ] Never use global statistics (mean, std) computed on full data\n",
    "\n",
    "## Feature Engineering\n",
    "- [ ] Create features using train data only\n",
    "- [ ] No target-derived features (e.g., target mean encoding without CV)\n",
    "- [ ] No future information (temporal leakage)\n",
    "- [ ] No identifiers that proxy for target\n",
    "\n",
    "## Model Training\n",
    "- [ ] Train on train set only\n",
    "- [ ] Tune hyperparameters using validation set\n",
    "- [ ] Use cross-validation for robust tuning\n",
    "- [ ] Never touch test set until final evaluation\n",
    "\n",
    "## Evaluation\n",
    "- [ ] Report train/val/test metrics separately\n",
    "- [ ] Check for reasonable train-val gap (0.01-0.10 typical)\n",
    "- [ ] Investigate if val AUC > 0.99 (suspiciously high)\n",
    "- [ ] Verify performance is consistent across CV folds\n",
    "\n",
    "## Code Review\n",
    "- [ ] All preprocessing inside Pipeline\n",
    "- [ ] No .fit() calls on val/test data\n",
    "- [ ] No global scaling before split\n",
    "- [ ] Random states fixed for reproducibility\n",
    "\n",
    "## Production Deployment\n",
    "- [ ] Save entire pipeline (not just model)\n",
    "- [ ] Use pipeline.transform() for new data\n",
    "- [ ] Monitor for distribution shift\n",
    "- [ ] Retrain periodically with proper splits\n",
    "\"\"\"\n",
    "\n",
    "# Save checklist\n",
    "with open(reports_dir / '02_leakage_checklist.md', 'w') as f:\n",
    "    f.write(leakage_checklist)\n",
    "\n",
    "print(\"üìã Leakage Prevention Checklist\")\n",
    "print(\"=\" * 60)\n",
    "print(leakage_checklist)\n",
    "print(f\"\\n‚úÖ Checklist saved to: {reports_dir / '02_leakage_checklist.md'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee37f50",
   "metadata": {},
   "source": [
    "## 10. Time-Based Splits (Bonus)\n",
    "\n",
    "**When temporal ordering matters** (time series, transactions), use time-based splits.\n",
    "\n",
    "**Our dataset**: Particle collisions are i.i.d. (no temporal ordering), so random stratified split is appropriate.\n",
    "\n",
    "**For time series**:\n",
    "```python\n",
    "# Example (not run):\n",
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "# tscv = TimeSeriesSplit(n_splits=5)\n",
    "# for train_idx, val_idx in tscv.split(X):\n",
    "#     # Train on past, validate on future\n",
    "#     X_train, X_val = X[train_idx], X[val_idx]\n",
    "```\n",
    "\n",
    "**Key difference**: Don't shuffle! Preserve temporal order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944d46ca",
   "metadata": {},
   "source": [
    "## 11. Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b146c7",
   "metadata": {},
   "source": [
    "**Exercise 1**: Identify the leakage\n",
    "\n",
    "Which of these pipelines has data leakage? Explain why.\n",
    "\n",
    "```python\n",
    "# Pipeline A\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # Full data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Pipeline B\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0dbd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here:\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0aaab4",
   "metadata": {},
   "source": [
    "**Exercise 2**: Implement a safe preprocessing pipeline\n",
    "\n",
    "Create a sklearn Pipeline that:\n",
    "1. Imputes missing values with median (train-fitted)\n",
    "2. Standardizes features (train-fitted)\n",
    "3. Trains a logistic regression model\n",
    "\n",
    "Verify with assertions that no leakage occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942b7997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your implementation here:\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ce7416",
   "metadata": {},
   "source": [
    "**Exercise 3**: Design a split strategy for a time-series problem\n",
    "\n",
    "You have transaction fraud data with timestamps:\n",
    "- 1M transactions over 2 years\n",
    "- Goal: Predict fraud in next month\n",
    "- Transactions have temporal autocorrelation (fraud waves)\n",
    "\n",
    "Design a proper train/val/test split strategy. Consider:\n",
    "1. Should you shuffle?\n",
    "2. How to split temporally?\n",
    "3. How to handle data drift?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c72817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here:\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9311c4",
   "metadata": {},
   "source": [
    "---\n",
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8bdebe",
   "metadata": {},
   "source": [
    "**Solution 1**: Identify the leakage\n",
    "\n",
    "**Answer**: Pipeline A has leakage ‚ùå\n",
    "\n",
    "**Explanation**:\n",
    "```python\n",
    "# Pipeline A (LEAKY ‚ùå)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # ‚Üê LEAKAGE HERE!\n",
    "# Problem: Scaler computes mean/std using ENTIRE dataset (train + test)\n",
    "# Test data influences scaling parameters ‚Üí indirect information leak\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y)\n",
    "# Even though we split after, scaling already \"saw\" test data\n",
    "```\n",
    "\n",
    "**Pipeline B is correct** ‚úÖ:\n",
    "```python\n",
    "# Pipeline B (CORRECT ‚úÖ)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# Split BEFORE any preprocessing\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Fits on train only\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "# pipeline.fit() calls scaler.fit_transform(X_train), not X_test\n",
    "# pipeline.predict() calls scaler.transform(X_test) using train statistics\n",
    "```\n",
    "\n",
    "**The fix**: Always split BEFORE preprocessing, or use Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5786361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1 (demonstration)\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Demonstrate correct order\n",
    "print(\"‚úÖ CORRECT ORDER:\")\n",
    "print(\"1. Split data\")\n",
    "print(\"2. Create Pipeline\")\n",
    "print(\"3. Fit Pipeline on train\")\n",
    "print(\"4. Evaluate on val/test\")\n",
    "print(\"\\n‚ùå WRONG ORDER:\")\n",
    "print(\"1. Preprocess full data\")\n",
    "print(\"2. Split preprocessed data\")\n",
    "print(\"3. Train model\")\n",
    "print(\"   ‚Üí Leakage: preprocessing used test data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d081d5",
   "metadata": {},
   "source": [
    "**Solution 2**: Implement safe preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9a1912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 2\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create safe pipeline\n",
    "safe_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Fit on train\n",
    "    ('scaler', StandardScaler()),                    # Fit on train\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Split data\n",
    "X_train_ex, X_test_ex, y_train_ex, y_test_ex = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Fit pipeline\n",
    "safe_pipeline.fit(X_train_ex, y_train_ex)\n",
    "\n",
    "# Verify no leakage with assertions\n",
    "print(\"üîç Leakage Verification:\")\n",
    "\n",
    "# Check 1: Imputer statistics computed from train only\n",
    "imputer_stats = safe_pipeline.named_steps['imputer'].statistics_\n",
    "print(f\"‚úÖ Imputer median computed from {X_train_ex.shape[0]} train samples\")\n",
    "\n",
    "# Check 2: Scaler statistics computed from train only\n",
    "scaler_mean = safe_pipeline.named_steps['scaler'].mean_\n",
    "print(f\"‚úÖ Scaler mean computed from {X_train_ex.shape[0]} train samples\")\n",
    "\n",
    "# Check 3: Predictions work on test\n",
    "y_pred_test = safe_pipeline.predict_proba(X_test_ex)[:, 1]\n",
    "auc_test = roc_auc_score(y_test_ex, y_pred_test)\n",
    "print(f\"‚úÖ Test AUC: {auc_test:.4f}\")\n",
    "\n",
    "# Check 4: Verify imputer/scaler were not refit on test\n",
    "# (No way to directly check, but we can verify pipeline behavior)\n",
    "assert hasattr(safe_pipeline, 'named_steps'), \"Pipeline structure exists\"\n",
    "assert 'imputer' in safe_pipeline.named_steps, \"Imputer in pipeline\"\n",
    "assert 'scaler' in safe_pipeline.named_steps, \"Scaler in pipeline\"\n",
    "\n",
    "print(\"\\n‚úÖ All assertions passed: No leakage detected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3586a7be",
   "metadata": {},
   "source": [
    "**Solution 3**: Time-series split strategy\n",
    "\n",
    "**Strategy for fraud detection with temporal data**:\n",
    "\n",
    "```\n",
    "Timeline: 2021-01 to 2022-12 (24 months)\n",
    "\n",
    "Train:    2021-01 to 2022-06 (18 months) ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
    "Val:      2022-07 to 2022-09 (3 months)                    ‚îÅ‚îÅ‚îÅ‚îì\n",
    "Test:     2022-10 to 2022-12 (3 months)                        ‚îÅ‚îÅ‚îÅ\n",
    "                                                        (predict)\n",
    "```\n",
    "\n",
    "**Key decisions**:\n",
    "\n",
    "1. **No shuffling** ‚ùå\n",
    "   - Preserve temporal order\n",
    "   - Train on past, predict future\n",
    "   \n",
    "2. **Temporal split**:\n",
    "   ```python\n",
    "   # Sort by timestamp\n",
    "   df_sorted = df.sort_values('timestamp')\n",
    "   \n",
    "   # Split by date ranges\n",
    "   train_end = '2022-06-30'\n",
    "   val_end = '2022-09-30'\n",
    "   \n",
    "   train = df_sorted[df_sorted['timestamp'] <= train_end]\n",
    "   val = df_sorted[(df_sorted['timestamp'] > train_end) & \n",
    "                   (df_sorted['timestamp'] <= val_end)]\n",
    "   test = df_sorted[df_sorted['timestamp'] > val_end]\n",
    "   ```\n",
    "\n",
    "3. **Handling data drift**:\n",
    "   - Monitor train vs. val distribution shift\n",
    "   - Use expanding window: retrain monthly with all past data\n",
    "   - Track feature importance changes over time\n",
    "   \n",
    "4. **Validation strategy**:\n",
    "   - Use TimeSeriesSplit for hyperparameter tuning\n",
    "   - Multiple temporal folds to catch seasonality\n",
    "   \n",
    "5. **Production considerations**:\n",
    "   - Retrain model monthly with expanding window\n",
    "   - Monitor for distribution shift (PSI, KS test)\n",
    "   - Have fallback to rules if model degrades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d1649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 3 (code template)\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Simulated time-series split (conceptual)\n",
    "print(\"Time-Series Split Strategy:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create temporal indices (simulate 24 months)\n",
    "n_samples = len(X)\n",
    "time_indices = np.arange(n_samples)\n",
    "\n",
    "# TimeSeriesSplit for CV\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "print(\"TimeSeriesSplit Cross-Validation Folds:\")\n",
    "for i, (train_idx, val_idx) in enumerate(tscv.split(time_indices)):\n",
    "    train_months = len(train_idx) / (n_samples / 24)\n",
    "    val_months = len(val_idx) / (n_samples / 24)\n",
    "    print(f\"Fold {i+1}:\")\n",
    "    print(f\"  Train: {len(train_idx):,} samples (~{train_months:.1f} months)\")\n",
    "    print(f\"  Val:   {len(val_idx):,} samples (~{val_months:.1f} months)\")\n",
    "\n",
    "print(\"\\nüîë Key Principles:\")\n",
    "print(\"  1. ‚úÖ No shuffling (preserve temporal order)\")\n",
    "print(\"  2. ‚úÖ Train on past, validate on future\")\n",
    "print(\"  3. ‚úÖ Expanding window (not sliding)\")\n",
    "print(\"  4. ‚úÖ Monitor distribution shift\")\n",
    "print(\"  5. ‚úÖ Retrain periodically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646c0250",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Notebook Complete!\n",
    "\n",
    "**What you learned**:\n",
    "1. ‚úÖ Proper train/val/test splits with stratification\n",
    "2. ‚úÖ K-fold cross-validation for robust evaluation\n",
    "3. ‚úÖ Data leakage: how it happens and how to prevent it\n",
    "4. ‚úÖ sklearn Pipelines as leakage prevention tool\n",
    "5. ‚úÖ Sanity checks to detect leakage\n",
    "6. ‚úÖ Time-based splits for temporal data\n",
    "\n",
    "**Outputs saved**:\n",
    "- `reports/02_leaky_vs_correct.png`\n",
    "- `reports/02_leakage_checklist.md`\n",
    "\n",
    "**Key takeaway**: Always use `sklearn.pipeline.Pipeline` to encapsulate preprocessing. Split BEFORE preprocessing.\n",
    "\n",
    "**Next notebook**: `03_baselines_and_metrics_that_matter.ipynb` ‚Äî Learn to establish baselines and choose metrics that align with business goals."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
