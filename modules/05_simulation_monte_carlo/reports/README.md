# Module 05: Simulation & Monte Carlo - Notebook Outputs

This directory contains all plots, tables, and summaries generated by the educational notebooks.

## Generated Files (after running notebooks)

### From Notebook 01 (MC Integration & Error Bars):
- `01_simple_convergence.png` - Convergence of x² integral with CI bands + log-log error
- `01_convergence_analysis.png` - Average error over 20 independent runs

**Key findings:**
- Error decreases as O(N^{-1/2}) regardless of dimension
- 95% CI has ~95% coverage over repeated trials
- 5D sphere volume estimated with 1% accuracy using 100k samples

---

### From Notebook 02 (Importance Sampling):
- `02_importance_sampling_comparison.png` - Naive vs IS for tail probability
  - Left: Sampling distributions showing proposal shift
  - Right: Convergence comparison (20-50x speedup)

**Key findings:**
- IS achieves 20-50x variance reduction for P(X > 3)
- Proposal choice critical: good (μ=3) vs bad (μ=0, VRF<1)
- Always use log-space weights to avoid underflow

---

### From Notebook 03 (Control Variates & Antithetic):
- `03_control_variates.png` - Correlation structure + VRF vs ρ
  - Left: Scatter showing target-control correlation
  - Right: VRF = 1/(1-ρ²) curve

**Key findings:**
- VRF = 2-5x for Asian options (arithmetic vs geometric mean)
- Antithetic sampling: 1.5-2x improvement for monotone functions
- Need ρ > 0.5 for significant CV gains

---

### From Notebook 04 (Rare Events):
- `04_rare_events_comparison.png` - Naive MC breakdown + IS rescue
  - Left: Sampling distributions (proposal shifted to tail)
  - Right: Error convergence (100x speedup)

**Key findings:**
- P(Z > 4) ≈ 3×10^-5 estimated with 100x variance reduction
- Adaptive sampling automatically determines N for target accuracy
- Zero hits ≠ zero probability (Rule of Three: P < 3/N)

---

### From Notebook 05 (Synthetic Data):
- `05_brownian_motion.png` - Sample paths + distribution at t=10
- `05_ou_process.png` - Mean reversion for different θ values
- `05_levy_flights.png` - Heavy-tailed jumps (α = 0.5, 1.0, 1.5, 2.0)
- `05_physics_regression_problems.png` - 3 datasets: oscillator, projectile, heat
- `05_ml_predictions.png` - Model predictions vs noisy obs & ground truth
- `05_correlated_noise.png` - IID vs OU-based correlated noise

**Key findings:**
- Synthetic data enables true error measurement (vs ground truth)
- OU process with θ=2 gives realistic autocorrelated noise
- Random Forest achieves RMSE ≈ 0.05 on pendulum energy (noise=0.1)

---

## Summary Statistics

| Method | Problem | Samples | VRF | Time (s) |
|--------|---------|---------|-----|----------|
| Naive MC | 1D integral | 10k | 1.0x | 0.01 |
| IS | Tail P(X>3) | 10k | 20-50x | 0.02 |
| CV | Asian option | 10k | 2-5x | 0.03 |
| Antithetic | exp(X) | 5k | 1.5-2x | 0.01 |
| IS | Rare P(X>4) | 10k | 100x | 0.02 |

**Key message:** Variance reduction methods provide 10-100x speedup → equivalent to 100x-10000x more naive samples!

---

## Reproducing Results

All results are reproducible with fixed seeds (seed=42 throughout).

```bash
# Run all notebooks
jupyter nbconvert --execute --to notebook \
    --inplace modules/05_simulation_monte_carlo/notebooks/*.ipynb

# Or run individually in VS Code Jupyter extension
```

**Expected runtime:** ~10-15 minutes total for all 5 notebooks on CPU.
